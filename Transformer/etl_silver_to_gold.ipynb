{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69e7b82",
   "metadata": {},
   "source": [
    "# ETL (Extrair, Transformar e Carregar) da camada Silver para Gold.\n",
    "\n",
    "Este notebook realiza o processo de ETL para transformar e carregar os dados da camada Silver para a camada Gold no data lake. A camada Gold é otimizada para consultas analíticas e relatórios, garantindo que os dados estejam prontos para uso por ferramentas de BI e análise avançada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca037c69",
   "metadata": {},
   "source": [
    "### Configuração do Ambiente de Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark\n",
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ea172",
   "metadata": {},
   "source": [
    "# Criação e Carga das Dimensões (Star Schema)\n",
    "\n",
    "Esta seção tem como objetivo realizar a **criação e carga das tabelas dimensão**\n",
    "da camada Gold, seguindo o modelo **Star Schema**, a partir de dados previamente\n",
    "tratados na camada Silver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10d29f",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas\n",
    "\n",
    "Nesta seção são importadas as bibliotecas necessárias para:\n",
    "- manipulação de dados com PySpark\n",
    "- criação de colunas derivadas\n",
    "- conexão com o banco PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from psycopg2 import execute_batch, extras\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, concat_ws, year, month, dayofmonth, quarter, \n",
    "    dayofweek, when, date_format, monotonically_increasing_id,\n",
    "    lit, trim, upper\n",
    ")\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.sql.types import StringType, IntegerType, DateType, DecimalType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647b0e7",
   "metadata": {},
   "source": [
    "### Configuração do Ambiente\n",
    "\n",
    "Nesta etapa são configurados:\n",
    "- a sessão Spark\n",
    "- a conexão JDBC com o PostgreSQL\n",
    "- o schema de destino da camada Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SilverToGold\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "POSTGRES_HOST = \"localhost\"\n",
    "POSTGRES_PORT = \"5432\"\n",
    "POSTGRES_DB = \"cat_db\"\n",
    "POSTGRES_USER = \"admin\"\n",
    "POSTGRES_PASSWORD = \"admin\"\n",
    "\n",
    "conn_params = {\n",
    "    \"host\": POSTGRES_HOST,\n",
    "    \"database\": POSTGRES_DB,\n",
    "    \"user\": POSTGRES_USER,\n",
    "    \"password\": POSTGRES_PASSWORD,\n",
    "    \"port\": POSTGRES_PORT\n",
    "}\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "\n",
    "connection_properties = {\n",
    "    \"user\": POSTGRES_USER,\n",
    "    \"password\": POSTGRES_PASSWORD,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    \n",
    "    query = \"SELECT * FROM ACIDENTE\"\n",
    "    \n",
    "    pdf = pd.read_sql(query, conn)\n",
    "    df_silver = spark.createDataFrame(pdf)\n",
    "    \n",
    "    print(\"Dados da camada Silver carregados\")\n",
    "    df_silver.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro na leitura: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        \n",
    "GOLD_SCHEMA = \"gold\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc6e0d",
   "metadata": {},
   "source": [
    "### Função Genérica de Carga de Dimensões\n",
    "\n",
    "Esta função padroniza o processo de carga das dimensões, garantindo:\n",
    "- remoção de duplicidades\n",
    "- preservação da business key\n",
    "- inserção no schema Gold\n",
    "- validação básica pós-carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4871cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dimension(\n",
    "    df_dim,\n",
    "    dim_name,\n",
    "    id_col_silver,\n",
    "    other_cols,\n",
    "    pg_conn_params,\n",
    "    cols_to_drop=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Salva dados em uma dimensão no PostgreSQL usando psycopg2,\n",
    "    preservando a business key.\n",
    "    Retorna um DataFrame Spark da dimensão carregada (com surrogate keys).\n",
    "    \"\"\"\n",
    "\n",
    "    table_name = f\"{GOLD_SCHEMA}.dim_{dim_name}\"\n",
    "    business_key_col = f\"chv_{dim_name}_org\"\n",
    "\n",
    "    # Preparação da dimensão no Spark\n",
    "    df_dim_unique = (\n",
    "        df_dim\n",
    "        .select(col(id_col_silver).alias(business_key_col), *other_cols)\n",
    "        .distinct()\n",
    "        .dropna(subset=[business_key_col])\n",
    "    )\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_dim_unique = df_dim_unique.drop(*cols_to_drop)\n",
    "\n",
    "    print(f\"\\n---> Criando e carregando Dimensão: {table_name}\")\n",
    "    count_unique = df_dim_unique.count()\n",
    "    print(f\"     Registros únicos: {count_unique}\")\n",
    "\n",
    "    if count_unique == 0:\n",
    "        print(\"DataFrame vazio\")\n",
    "        return None\n",
    "\n",
    "    # Converter para Pandas para inserção via psycopg2\n",
    "    pdf = df_dim_unique.toPandas()\n",
    "\n",
    "    columns = list(pdf.columns)\n",
    "    cols_sql = \", \".join(columns)\n",
    "    values_sql = \", \".join([f\"%({c})s\" for c in columns])\n",
    "\n",
    "    insert_sql = f\"\"\"\n",
    "        INSERT INTO {table_name} ({cols_sql})\n",
    "        VALUES ({values_sql})\n",
    "        ON CONFLICT ({business_key_col}) DO NOTHING\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Conexão PostgreSQL\n",
    "        with psycopg2.connect(**pg_conn_params) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                execute_batch(\n",
    "                    cur,\n",
    "                    insert_sql,\n",
    "                    pdf.to_dict(orient=\"records\"),\n",
    "                    page_size=1000\n",
    "                )\n",
    "            conn.commit()\n",
    "\n",
    "        print(\"Inserção concluída\")\n",
    "\n",
    "        # Recarregar dimensão com surrogate keys via Spark\n",
    "        df_dim_loaded = spark.read \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .option(\"url\", jdbc_url) \\\n",
    "            .option(\"dbtable\", table_name) \\\n",
    "            .options(**connection_properties) \\\n",
    "            .load()\n",
    "\n",
    "        count_check = df_dim_loaded.count()\n",
    "\n",
    "        if count_check >= count_unique:\n",
    "            print(f\"Dimensão carregada. Registros confirmados: {count_check}\")\n",
    "        else:\n",
    "            print(f\"Confirmados ({count_check}) < esperados ({count_unique})\")\n",
    "\n",
    "        return df_dim_loaded\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gravar dimensão {table_name}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9a9a6",
   "metadata": {},
   "source": [
    "### Dimensão Tempo\n",
    "\n",
    "A dimensão tempo é utilizada para:\n",
    "- data do acidente\n",
    "- data de emissão da CAT\n",
    "- data de nascimento do trabalhador\n",
    "\n",
    "Ela permite análises temporais como sazonalidade, tendências e comparações anuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97362879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_tempo(df_silver):\n",
    "    \"\"\"\n",
    "    Cria dimensão tempo a partir de todas as datas do dataset.\n",
    "    Usada como role-playing para: data_acidente, data_emissao, data_nascimento.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão Tempo\")\n",
    "    \n",
    "    # Coleta todas as datas distintas\n",
    "    df_datas = df_silver.select(\"data_acidente\").distinct() \\\n",
    "        .union(df_silver.select(\"data_emissao\").distinct()) \\\n",
    "        .union(df_silver.select(\"data_nascimento\").distinct()) \\\n",
    "        .withColumnRenamed(\"data_acidente\", \"data\") \\\n",
    "        .distinct() \\\n",
    "        .dropna()\n",
    "    \n",
    "    # Enriquece com atributos temporais\n",
    "    df_tempo = df_datas.select(\n",
    "        col(\"data\"),\n",
    "        dayofmonth(\"data\").alias(\"dia\"),\n",
    "        month(\"data\").alias(\"mes\"),\n",
    "        date_format(\"data\", \"MMMM\").alias(\"nome_mes\"),\n",
    "        quarter(\"data\").alias(\"trimestre\"),\n",
    "        year(\"data\").alias(\"ano\"),\n",
    "        dayofweek(\"data\").alias(\"dia_semana\"),\n",
    "        when(dayofweek(\"data\").isin(1, 7), True).otherwise(False).alias(\"is_fim_semana\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_tempo,\n",
    "        \"tempo\",\n",
    "        \"data\",\n",
    "        [\"dia\", \"mes\", \"nome_mes\", \"trimestre\", \"ano\", \"dia_semana\", \"is_fim_semana\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d636630",
   "metadata": {},
   "source": [
    "### Dimensão Trabalhador\n",
    "\n",
    "Representa características demográficas e ocupacionais do trabalhador\n",
    "no momento do acidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_trabalhador(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão com dados do trabalhador acidentado.\n",
    "    Referencia: dim_cbo e dim_tempo (data_nascimento).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão Trabalhador\")\n",
    "    \n",
    "    df_trabalhador = df_silver.select(\n",
    "        \"id_trabalhador\",\n",
    "        upper(trim(col(\"sexo\"))).alias(\"sexo\"),\n",
    "        col(\"codigo_cbo\").alias(\"fk_cbo\"),\n",
    "        col(\"data_nascimento\").alias(\"fk_tempo_nascimento\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_trabalhador,\n",
    "        \"trabalhador\",\n",
    "        \"id_trabalhador\",\n",
    "        [\"sexo\", \"fk_cbo\", \"fk_tempo_nascimento\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e7142",
   "metadata": {},
   "source": [
    "### Dimensão Empregador\n",
    "\n",
    "A dimensão empregador representa as características da empresa\n",
    "responsável pelo vínculo de trabalho no momento do acidente.\n",
    "\n",
    "Esta dimensão referencia:\n",
    "- a dimensão CNAE (atividade econômica)\n",
    "- a dimensão Município (localização do empregador)\n",
    "\n",
    "Sua criação ocorre após a carga das dimensões independentes,\n",
    "garantindo integridade referencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fab3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_empregador(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão do empregador.\n",
    "    Referencia: dim_cnae e dim_municipio.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão Empregador\")\n",
    "    \n",
    "    df_empregador = df_silver.select(\n",
    "        col(\"id_empregador\"),\n",
    "        col(\"codigo_cnae\").alias(\"fk_cnae\"),\n",
    "        col(\"codigo_municipio_empregador\").alias(\"fk_municipio\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_empregador,\n",
    "        \"empregador\",\n",
    "        \"id_empregador\",\n",
    "        [\"fk_cnae\", \"fk_municipio\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7ebba",
   "metadata": {},
   "source": [
    "### Dimensões de Classificação\n",
    "\n",
    "As dimensões a seguir representam classificações oficiais utilizadas\n",
    "para padronização e análise estatística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa325a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_cbo(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão com códigos e descrições da CBO.\n",
    "    Origem: campo codigo_cbo e descricao_cbo da Silver.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão CBO\")\n",
    "    \n",
    "    df_cbo = df_silver.select(\n",
    "        col(\"codigo_cbo\").alias(\"id_cbo\"),\n",
    "        col(\"codigo_cbo\").alias(\"codigo\"),\n",
    "        col(\"descricao_cbo\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cbo,\n",
    "        \"cbo\",\n",
    "        \"id_cbo\",\n",
    "        [\"codigo\", \"descricao\"]\n",
    "    )\n",
    "    \n",
    "def create_dim_cnae(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão com códigos CNAE da atividade econômica do empregador.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão CNAE...\")\n",
    "    \n",
    "    df_cnae = df_silver.select(\n",
    "        col(\"codigo_cnae\").alias(\"id_cnae\"),\n",
    "        col(\"codigo_cnae\").alias(\"codigo\"),\n",
    "        col(\"descricao_cnae\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cnae,\n",
    "        \"cnae\",\n",
    "        \"id_cnae\",\n",
    "        [\"codigo\", \"descricao\"]\n",
    "    )\n",
    "    \n",
    "def create_dim_cid10(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão com códigos CID-10 (Classificação Internacional de Doenças).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão CID-10\")\n",
    "    \n",
    "    df_cid = df_silver.select(\n",
    "        col(\"codigo_cid10\").alias(\"id_cid10\"),\n",
    "        col(\"codigo_cid10\").alias(\"codigo\"),\n",
    "        col(\"descricao_cid10\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cid,\n",
    "        \"cid10\",\n",
    "        \"id_cid10\",\n",
    "        [\"codigo\", \"descricao\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfc0b7",
   "metadata": {},
   "source": [
    "### Dimensão Município\n",
    "\n",
    "A dimensão município é utilizada para:\n",
    "- local do acidente\n",
    "- local do empregador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_municipio(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão de municípios.\n",
    "    Usada como role-playing para: local_acidente e local_empregador.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão Município\")\n",
    "    \n",
    "    # União de municípios do acidente e do empregador\n",
    "    df_mun_acidente = df_silver.select(\n",
    "        col(\"codigo_municipio_acidente\").alias(\"codigo_ibge\"),\n",
    "        col(\"municipio_acidente\").alias(\"nome\"),\n",
    "        col(\"uf_acidente\").alias(\"uf\")\n",
    "    )\n",
    "    \n",
    "    df_mun_empregador = df_silver.select(\n",
    "        col(\"codigo_municipio_empregador\").alias(\"codigo_ibge\"),\n",
    "        col(\"municipio_empregador\").alias(\"nome\"),\n",
    "        col(\"uf_empregador\").alias(\"uf\")\n",
    "    )\n",
    "    \n",
    "    df_municipio = df_mun_acidente.union(df_mun_empregador) \\\n",
    "        .distinct() \\\n",
    "        .dropna(subset=[\"codigo_ibge\"])\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_municipio,\n",
    "        \"municipio\",\n",
    "        \"codigo_ibge\",\n",
    "        [\"nome\", \"uf\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003ff7f",
   "metadata": {},
   "source": [
    "### Dimensões de Caracterização do Acidente\n",
    "\n",
    "Estas dimensões descrevem o contexto e as causas do acidente de trabalho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_tipo_acidente(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão com tipos de acidente (típico, trajeto, doença).\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão Tipo de Acidente\")\n",
    "    \n",
    "    df_tipo_acidente = df_silver.select(\n",
    "        col(\"codigo_tipo_acidente\").alias(\"id_tipo_acidente\"),\n",
    "        col(\"descricao_tipo_acidente\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_tipo_acidente,\n",
    "        \"tipo_acidente\",\n",
    "        \"id_tipo_acidente\",\n",
    "        [\"descricao\"]\n",
    "    )\n",
    "    \n",
    "def create_dim_lesao(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão com informações sobre a lesão sofrida.\n",
    "    Combina natureza da lesão e parte do corpo atingida.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão Lesão\")\n",
    "    \n",
    "    df_lesao = df_silver.select(\n",
    "        concat_ws(\"_\", col(\"codigo_natureza_lesao\"), col(\"codigo_parte_corpo\")).alias(\"id_lesao\"),\n",
    "        col(\"descricao_natureza_lesao\").alias(\"natureza_lesao\"),\n",
    "        col(\"descricao_parte_corpo\").alias(\"parte_corpo_atingida\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_lesao,\n",
    "        \"lesao\",\n",
    "        \"id_lesao\",\n",
    "        [\"natureza_lesao\", \"parte_corpo_atingida\"]\n",
    "    )\n",
    "    \n",
    "def create_dim_agente_causador(df_silver):\n",
    "    \"\"\"\n",
    "    Dimensão com o agente causador do acidente.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCriando Dimensão Agente Causador\")\n",
    "    \n",
    "    df_agente = df_silver.select(\n",
    "        col(\"codigo_agente_causador\").alias(\"id_agente_causador\"),\n",
    "        col(\"descricao_agente_causador\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_agente,\n",
    "        \"agente_causador\",\n",
    "        \"id_agente_causador\",\n",
    "        [\"descricao\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e3256",
   "metadata": {},
   "source": [
    "## Execução da Carga das Dimensões\n",
    "\n",
    "Nesta etapa é executado o processo completo de criação e carga das dimensões,\n",
    "respeitando a ordem de dependência entre elas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CARGA DAS DIMENSÕES - STAR SCHEMA\")\n",
    "print(\"=\"*60)\n",
    "    \n",
    "try:\n",
    "    dim_tempo = create_dim_tempo(df_silver)          \n",
    "    dim_cbo = create_dim_cbo(df_silver)            \n",
    "    dim_municipio = create_dim_municipio(df_silver)      \n",
    "    dim_cnae = create_dim_cnae(df_silver)           \n",
    "    dim_tipo_acidente = create_dim_tipo_acidente(df_silver)  \n",
    "    dim_lesao = create_dim_lesao(df_silver)          \n",
    "    dim_agente_causador = create_dim_agente_causador(df_silver)\n",
    "    dim_cid10 = create_dim_cid10(df_silver)          \n",
    "\n",
    "    # Dimensões com FKs\n",
    "    dim_trabalhador = create_dim_trabalhador(df_silver)\n",
    "    dim_empregador = create_dim_empregador(df_silver)\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DIMENSÕES FORAM CARREGADAS\")\n",
    "    print(\"=\"*60)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nERRO NA CARGA DAS DIMENSÕES: {e}\")\n",
    "    raise e\n",
    "    \n",
    "finally:\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5dbab",
   "metadata": {},
   "source": [
    "### Preparando dados da camada Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661cdb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df_silver.select(\n",
    "    # Business key\n",
    "    \"id_cat\",\n",
    "    \n",
    "    # Campos para lookup de FKs\n",
    "    \"data_acidente\",\n",
    "    \"data_emissao\",\n",
    "    \"data_nascimento\",\n",
    "    \"id_trabalhador\",\n",
    "    \"codigo_cbo\",\n",
    "    \"id_empregador\",\n",
    "    \"codigo_cnae\",\n",
    "    \"codigo_municipio_acidente\",\n",
    "    \"codigo_municipio_empregador\",\n",
    "    \"codigo_tipo_acidente\",\n",
    "    col(\"codigo_natureza_lesao\"),\n",
    "    col(\"codigo_parte_corpo\"),\n",
    "    \"codigo_agente_causador\",\n",
    "    \"codigo_cid10\",\n",
    "    \n",
    "    # Métricas\n",
    "    col(\"dias_afastamento\").cast(IntegerType()).alias(\"dias_afastamento\"),\n",
    "    col(\"valor_indenizacao\").cast(DecimalType(15,2)).alias(\"valor_indenizacao\"),\n",
    "    col(\"idade_trabalhador\").cast(IntegerType()).alias(\"idade_trabalhador\"),\n",
    "    \n",
    "    # Flags\n",
    "    when(col(\"houve_obito\") == \"S\", 1).otherwise(0).alias(\"flag_obito\"),\n",
    "    when(col(\"houve_afastamento\") == \"S\", 1).otherwise(0).alias(\"flag_afastamento\"),\n",
    "    when(col(\"comunicacao_policia\") == \"S\", 1).otherwise(0).alias(\"flag_comunicacao_policia\"),\n",
    "    when(col(\"acidente_trajeto\") == \"S\", 1).otherwise(0).alias(\"flag_trajeto\"),\n",
    "    when(col(\"primeira_cat\") == \"S\", 1).otherwise(0).alias(\"flag_primeira_cat\"),\n",
    "    when(col(\"cat_reabertura\") == \"S\", 1).otherwise(0).alias(\"flag_reabertura\"),\n",
    "    \n",
    "    # Indicadores\n",
    "    col(\"situacao_cat\"),\n",
    "    col(\"origem_cat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efedf27",
   "metadata": {},
   "source": [
    "### Lookup de Surrogate Keys nas Dimensões\n",
    "\n",
    "Neste passo, o pipeline realiza o mapeamento das chaves de negócio (business keys) presentes na base de fatos para as surrogate keys das respectivas tabelas de dimensão.\n",
    "Cada JOIN associa os registros do fato às dimensões corretas (tempo, trabalhador, empregador, localização, classificação e natureza do acidente), garantindo integridade referencial, padronização dimensional e compatibilidade com o modelo estrela no Data Warehouse.\n",
    "\n",
    "O processo é executado de forma incremental e controlada, com múltiplos joins à esquerda (LEFT JOIN), preservando todos os registros da fato mesmo quando alguma dimensão ainda não possui correspondência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"     [1/14] dim_tempo -> data_acidente\")\n",
    "df_fact = df_base.join(\n",
    "    dim_tempo.select(\n",
    "        col(\"id_tempo\").alias(\"fk_tempo_acidente\"),\n",
    "        col(\"chv_tempo_org\").alias(\"data_join_acidente\")\n",
    "    ),\n",
    "    df_base.data_acidente == col(\"data_join_acidente\"),\n",
    "    \"left\"\n",
    ").drop(\"data_join_acidente\")\n",
    "\n",
    "# Tempo - data de emissão\n",
    "print(\"     [2/14] dim_tempo -> data_emissao\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_tempo.select(\n",
    "        col(\"id_tempo\").alias(\"fk_tempo_emissao\"),\n",
    "        col(\"chv_tempo_org\").alias(\"data_join_emissao\")\n",
    "    ),\n",
    "    df_fact.data_emissao == col(\"data_join_emissao\"),\n",
    "    \"left\"\n",
    ").drop(\"data_join_emissao\")\n",
    "\n",
    "# Tempo - data de nascimento\n",
    "print(\"     [3/14] dim_tempo -> data_nascimento\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_tempo.select(\n",
    "        col(\"id_tempo\").alias(\"fk_tempo_nascimento\"),\n",
    "        col(\"chv_tempo_org\").alias(\"data_join_nascimento\")\n",
    "    ),\n",
    "    df_fact.data_nascimento == col(\"data_join_nascimento\"),\n",
    "    \"left\"\n",
    ").drop(\"data_join_nascimento\")\n",
    "\n",
    "# Trabalhador\n",
    "print(\"     [4/14] dim_trabalhador\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_trabalhador.select(\n",
    "        col(\"id_trabalhador\").alias(\"fk_trabalhador\"),\n",
    "        col(\"chv_trabalhador_org\").alias(\"id_trab_join\")\n",
    "    ),\n",
    "    df_fact.id_trabalhador == col(\"id_trab_join\"),\n",
    "    \"left\"\n",
    ").drop(\"id_trab_join\")\n",
    "\n",
    "# CBO\n",
    "print(\"     [5/14] dim_cbo\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_cbo.select(\n",
    "        col(\"id_cbo\").alias(\"fk_cbo\"),\n",
    "        col(\"chv_cbo_org\").alias(\"codigo_cbo_join\")\n",
    "    ),\n",
    "    df_fact.codigo_cbo == col(\"codigo_cbo_join\"),\n",
    "    \"left\"\n",
    ").drop(\"codigo_cbo_join\")\n",
    "\n",
    "# Empregador\n",
    "print(\"     [6/14] dim_empregador\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_empregador.select(\n",
    "        col(\"id_empregador\").alias(\"fk_empregador\"),\n",
    "        col(\"chv_empregador_org\").alias(\"id_emp_join\")\n",
    "    ),\n",
    "    df_fact.id_empregador == col(\"id_emp_join\"),\n",
    "    \"left\"\n",
    ").drop(\"id_emp_join\")\n",
    "\n",
    "# CNAE\n",
    "print(\"     [7/14] dim_cnae\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_cnae.select(\n",
    "        col(\"id_cnae\").alias(\"fk_cnae\"),\n",
    "        col(\"chv_cnae_org\").alias(\"codigo_cnae_join\")\n",
    "    ),\n",
    "    df_fact.codigo_cnae == col(\"codigo_cnae_join\"),\n",
    "    \"left\"\n",
    ").drop(\"codigo_cnae_join\")\n",
    "\n",
    "# Município - acidente\n",
    "print(\"     [8/14] dim_municipio -> acidente\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_municipio.select(\n",
    "        col(\"id_municipio\").alias(\"fk_municipio_acidente\"),\n",
    "        col(\"chv_municipio_org\").alias(\"mun_acidente_join\")\n",
    "    ),\n",
    "    df_fact.codigo_municipio_acidente == col(\"mun_acidente_join\"),\n",
    "    \"left\"\n",
    ").drop(\"mun_acidente_join\")\n",
    "\n",
    "# Município - empregador\n",
    "print(\"     [9/14] dim_municipio -> empregador\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_municipio.select(\n",
    "        col(\"id_municipio\").alias(\"fk_municipio_empregador\"),\n",
    "        col(\"chv_municipio_org\").alias(\"mun_empregador_join\")\n",
    "    ),\n",
    "    df_fact.codigo_municipio_empregador == col(\"mun_empregador_join\"),\n",
    "    \"left\"\n",
    ").drop(\"mun_empregador_join\")\n",
    "\n",
    "# Tipo de Acidente\n",
    "print(\"     [10/14] dim_tipo_acidente\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_tipo_acidente.select(\n",
    "        col(\"id_tipo_acidente\").alias(\"fk_tipo_acidente\"),\n",
    "        col(\"chv_tipo_acidente_org\").alias(\"tipo_acidente_join\")\n",
    "    ),\n",
    "    df_fact.codigo_tipo_acidente == col(\"tipo_acidente_join\"),\n",
    "    \"left\"\n",
    ").drop(\"tipo_acidente_join\")\n",
    "\n",
    "# Lesão\n",
    "print(\"     [11/14] dim_lesao\")\n",
    "df_fact = df_fact.withColumn(\n",
    "    \"lesao_join_key\",\n",
    "    concat_ws(\"_\", col(\"codigo_natureza_lesao\"), col(\"codigo_parte_corpo\"))\n",
    ")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_lesao.select(\n",
    "        col(\"id_lesao\").alias(\"fk_lesao\"),\n",
    "        col(\"chv_lesao_org\").alias(\"lesao_join\")\n",
    "    ),\n",
    "    df_fact.lesao_join_key == col(\"lesao_join\"),\n",
    "    \"left\"\n",
    ").drop(\"lesao_join\", \"lesao_join_key\")\n",
    "\n",
    "# Agente Causador\n",
    "print(\"     [12/14] dim_agente_causador\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_agente_causador.select(\n",
    "        col(\"id_agente_causador\").alias(\"fk_agente_causador\"),\n",
    "        col(\"chv_agente_causador_org\").alias(\"agente_join\")\n",
    "    ),\n",
    "    df_fact.codigo_agente_causador == col(\"agente_join\"),\n",
    "    \"left\"\n",
    ").drop(\"agente_join\")\n",
    "\n",
    "# CID-10\n",
    "print(\"     [13/14] dim_cid10\")\n",
    "df_fact = df_fact.join(\n",
    "    dim_cid10.select(\n",
    "        col(\"id_cid10\").alias(\"fk_cid10\"),\n",
    "        col(\"chv_cid10_org\").alias(\"cid_join\")\n",
    "    ),\n",
    "    df_fact.codigo_cid10 == col(\"cid_join\"),\n",
    "    \"left\"\n",
    ").drop(\"cid_join\")\n",
    "\n",
    "print(\"     [14/14] Lookups concluídos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c31259",
   "metadata": {},
   "source": [
    "### Montagem da Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4226f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_final = df_fact.select(\n",
    "    # Business Key\n",
    "    col(\"id_cat\").alias(\"chv_cat_org\"),\n",
    "    \n",
    "    # FKs - Tempo\n",
    "    \"fk_tempo_acidente\",\n",
    "    \"fk_tempo_emissao\",\n",
    "    \"fk_tempo_nascimento\",\n",
    "    \n",
    "    # FKs - Entidades\n",
    "    \"fk_trabalhador\",\n",
    "    \"fk_cbo\",\n",
    "    \"fk_empregador\",\n",
    "    \"fk_cnae\",\n",
    "    \n",
    "    # FKs - Localização\n",
    "    \"fk_municipio_acidente\",\n",
    "    \"fk_municipio_empregador\",\n",
    "    \n",
    "    # FKs - Características\n",
    "    \"fk_tipo_acidente\",\n",
    "    \"fk_lesao\",\n",
    "    \"fk_agente_causador\",\n",
    "    \"fk_cid10\",\n",
    "    \n",
    "    # Métricas\n",
    "    \"dias_afastamento\",\n",
    "    \"valor_indenizacao\",\n",
    "    \"idade_trabalhador\",\n",
    "    \n",
    "    # Flags\n",
    "    \"flag_obito\",\n",
    "    \"flag_afastamento\",\n",
    "    \"flag_comunicacao_policia\",\n",
    "    \"flag_trajeto\",\n",
    "    \"flag_primeira_cat\",\n",
    "    \"flag_reabertura\",\n",
    "    \n",
    "    # Indicadores\n",
    "    \"situacao_cat\",\n",
    "    \"origem_cat\"\n",
    ").distinct()\n",
    "\n",
    "count_fact = df_fact_final.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab941368",
   "metadata": {},
   "source": [
    "### Carga da Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = df_fact_final.columns\n",
    "fact_table_name = f\"{GOLD_SCHEMA}.fato_acidente_trabalho\"\n",
    "\n",
    "print(f\"Colunas: {len(colunas)}\")\n",
    "print(f\"Preparando dados para inserção...\")\n",
    "\n",
    "# Converter DataFrame para lista de tuplas\n",
    "dados_para_inserir = [tuple(row) for row in df_fact_final.collect()]\n",
    "print(f\"     Total de registros a inserir: {len(dados_para_inserir)}\")\n",
    "\n",
    "# Conexão e inserção via psycopg2\n",
    "conn = None\n",
    "cursor = None\n",
    "\n",
    "try:\n",
    "    print(f\"     Estabelecendo conexão com PostgreSQL\")\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(f\"     Iniciando inserção em lote usando execute_values\")\n",
    "    \n",
    "    # Montar query de INSERT\n",
    "    query = f\"INSERT INTO {fact_table_name} ({', '.join(colunas)}) VALUES %s\"\n",
    "    \n",
    "    # Execução em lote com execute_values\n",
    "    extras.execute_values(\n",
    "        cursor,\n",
    "        query,\n",
    "        dados_para_inserir,\n",
    "        template=None,\n",
    "        page_size=1000  # Insere 1000 registros por vez\n",
    "    )\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"Carga de {len(dados_para_inserir)} registros concluída\")\n",
    "    \n",
    "    # Validação pós-carga\n",
    "    print(\"\\nValidando carga\")\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {fact_table_name}\")\n",
    "    count_check = cursor.fetchone()[0]\n",
    "    print(f\"Registros confirmados no banco: {count_check}\")\n",
    "    \n",
    "    if count_check >= count_fact:\n",
    "        print(\"carga bem sucedida\")\n",
    "    else:\n",
    "        print(f\"Confirmados ({count_check}) < esperados ({count_fact})\")\n",
    "        \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nErro ao inserir dados: {e}\")\n",
    "    if conn:\n",
    "        conn.rollback()\n",
    "    raise e\n",
    "    \n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n",
    "    print(\"Conexão com PostgreSQL encerrada.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
