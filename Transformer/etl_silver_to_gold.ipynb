{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69e7b82",
   "metadata": {},
   "source": [
    "# ETL (Extrair, Transformar e Carregar) da camada Silver para Gold.\n",
    "\n",
    "Este notebook realiza o processo de ETL para transformar e carregar os dados da camada Silver para a camada Gold no data lake. A camada Gold √© otimizada para consultas anal√≠ticas e relat√≥rios, garantindo que os dados estejam prontos para uso por ferramentas de BI e an√°lise avan√ßada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca037c69",
   "metadata": {},
   "source": [
    "### Configura√ß√£o do Ambiente de Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ac6ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (4.1.1)\n",
      "Requirement already satisfied: py4j<0.10.9.10,>=0.10.9.7 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pyspark) (0.10.9.9)\n",
      "Requirement already satisfied: psycopg2 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (2.9.11)\n",
      "Requirement already satisfied: pandas in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pandas) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install psycopg2\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ea172",
   "metadata": {},
   "source": [
    "# Cria√ß√£o e Carga das Dimens√µes (Star Schema)\n",
    "\n",
    "Esta se√ß√£o tem como objetivo realizar a **cria√ß√£o e carga das tabelas dimens√£o**\n",
    "da camada Gold, seguindo o modelo **Star Schema**, a partir de dados previamente\n",
    "tratados na camada Silver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10d29f",
   "metadata": {},
   "source": [
    "### Importa√ß√£o de Bibliotecas\n",
    "\n",
    "Nesta se√ß√£o s√£o importadas as bibliotecas necess√°rias para:\n",
    "- manipula√ß√£o de dados com PySpark\n",
    "- cria√ß√£o de colunas derivadas\n",
    "- conex√£o com o banco PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617b271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from psycopg2.extras import execute_batch\n",
    "from psycopg2 import extras\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, concat_ws, year, month, dayofmonth, quarter, \n",
    "    dayofweek, when, date_format, monotonically_increasing_id,\n",
    "    lit, trim, upper\n",
    ")\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.sql.types import StringType, IntegerType, DateType, DecimalType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647b0e7",
   "metadata": {},
   "source": [
    "### Configura√ß√£o do Ambiente\n",
    "\n",
    "Nesta etapa s√£o configurados:\n",
    "- a sess√£o Spark\n",
    "- a conex√£o JDBC com o PostgreSQL\n",
    "- o schema de destino da camada Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ca19e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/17 15:14:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/01/17 15:14:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "/tmp/ipykernel_24707/1149729806.py:30: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados da camada Silver carregados\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:02 WARN TaskSetManager: Stage 0 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "Traceback (most recent call last):                                  (0 + 1) / 1]\n",
      "  File \"/home/yabamiah/Sandbox/cat-analytics/.venv/lib/python3.14/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "  File \"/home/yabamiah/Sandbox/cat-analytics/.venv/lib/python3.14/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+--------------------+--------------------+---------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------+---------------------+-----------------------+---------------+----------------+\n",
      "|agente_causador_acidente|data_acidente_referencia|cbo_codigo_descricao|              cid_10|cnae_empregador|cnae_empregador_descricao|municipio_empregador|      natureza_lesao|parte_corpo_atingida|     sexo|tipo_acidente|uf_municipio_acidente|uf_municipio_empregador|data_nascimento|data_emissao_cat|\n",
      "+------------------------+------------------------+--------------------+--------------------+---------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------+---------------------+-----------------------+---------------+----------------+\n",
      "|    Rua e Estrada - S...|              2023-03-27|       Administrador|   Frat da Clavicula|           4711|     Comercio Varejist...| S√£o Jos√© dos Campos|             Fratura|               Ombro|Masculino|      Trajeto|             Maranh√£o|              S√£o Paulo|     1977-06-05|      2023-05-01|\n",
      "|    Impacto de Pes. C...|              2023-04-30|  Tec. de Enfermagem|   Outr Locais Espec|           8610|     Atividades de Ate...|             Goi√¢nia|  Outras Lesoes, Nic|                Dedo| Feminino|       T√≠pico|     N√£o identificado|                  Goi√°s|     1992-08-08|      2023-05-01|\n",
      "|    Agente Infeccioso...|              2023-03-31|Analista de Desen...|Infecc p/Coronavi...|           8610|     Atividades de Ate...|        Porto Alegre|Doenca Contagiosa...|Aparelho Respirat...|Masculino|       Doen√ßa|     N√£o identificado|      Rio Grande do Sul|     1981-05-31|      2023-04-16|\n",
      "|    Chave de Porca ou...|              2023-04-15|    Inst. Tubula√ß√µes|     Frat do Polegar|           4322|     Instalacoes Hidra...|           Aragua√≠na|             Fratura|                Dedo|Masculino|       T√≠pico|              Sergipe|              Tocantins|     1994-10-20|      2023-05-01|\n",
      "|    Rua e Estrada - S...|              2023-04-28|Oper. M√°quina Cor...|Luxacao da Articu...|           2330|     Fabricacao de Art...|Campos dos Goytac...|             Luxacao|Tronco, Parte Mul...|Masculino|      Trajeto|            Tocantins|         Rio de Janeiro|     1993-08-21|      2023-05-01|\n",
      "|    Impacto Sofrido p...|              2023-04-27|Carpinteiro de Obras|Capsulite Adesiva...|           4120|     Construcao de Edi...|           S√£o Paulo|      Lesao Imediata|               Ombro|Masculino|       T√≠pico|             Maranh√£o|              S√£o Paulo|     1972-05-30|      2023-05-01|\n",
      "|        N√£o identificado|              2023-04-22|  Tec. de Enfermagem|Contato Exposicao...|           8610|     Atividades de Ate...|       Caxias do Sul|Corte, Laceracao,...|                Dedo| Feminino|       T√≠pico|     N√£o identificado|      Rio Grande do Sul|     1983-03-08|      2023-05-01|\n",
      "|    Impacto de Pes. C...|              2023-04-26|  Tec. de Enfermagem|   Contusao do Torax|           8610|     Atividades de Ate...|       Caxias do Sul|  Outras Lesoes, Nic|Partes Multiplas ...| Feminino|       T√≠pico|     N√£o identificado|      Rio Grande do Sul|     1985-05-14|      2023-05-01|\n",
      "|    Impacto Sofrido p...|              2023-04-28|Alimentador de Li...|Ferim de Regiao N...|           1071|     Fabricacao de Acu...|         Igreja Nova|Amputacao ou Enuc...|                Dedo|Masculino|       T√≠pico|     N√£o identificado|                Alagoas|     1992-01-03|      2023-05-01|\n",
      "|    Rua e Estrada - S...|              2023-04-13|Controlador de Pr...|Frat dos Ossos Na...|           4789|     Comercio Varejist...|Campos dos Goytac...|             Fratura|Nariz (Inclusive ...|Masculino|       T√≠pico|            Tocantins|         Rio de Janeiro|     1976-10-13|      2023-05-01|\n",
      "|            Maquina, Nic|              2023-04-27|         Carpinteiro|Hemorragia Subara...|           4330|      Obras de Acabamento|           S√£o Paulo|  Outras Lesoes, Nic|Cabeca, Partes Mu...|Masculino|       T√≠pico|             Maranh√£o|              S√£o Paulo|     1970-03-05|      2023-05-01|\n",
      "|    Veiculo Rodoviari...|              2023-04-26|        Coletor Lixo|           Dor Aguda|           3811|     Coleta de Residuo...|     Campo Grande-Ms|Contusao, Esmagam...|              Joelho|Masculino|       T√≠pico|     N√£o identificado|     Mato Grosso do Sul|     2001-12-28|      2023-05-01|\n",
      "|    Veiculo Rodoviari...|              2023-04-26|        Coletor Lixo|Entorse e Distens...|           3811|     Coleta de Residuo...|     Campo Grande-Ms|   Distensao, Torcao|Articulacao do To...|Masculino|       T√≠pico|     N√£o identificado|     Mato Grosso do Sul|     1996-07-24|      2023-05-01|\n",
      "|    Impacto de Pes. C...|              2023-04-26|    N√£o identificado|Contusao de Outr ...|           8511|     Educacao Infantil...|               Betim|Contusao, Esmagam...|Pe (Exceto Artelhos)| Feminino|       T√≠pico|             Rond√¥nia|           Minas Gerais|     1988-05-29|      2023-05-01|\n",
      "|    Impacto de Pes. C...|              2023-04-06|Motorista de Cami...|Traum Musc Flexor...|           4930|     Transporte Rodovi...|           S√£o Paulo|             Luxacao|Braco (Entre O Pu...|Masculino|       T√≠pico|             Maranh√£o|              S√£o Paulo|     1978-01-23|      2023-05-01|\n",
      "|    Ataque de Ser Viv...|              2023-04-11| Tratador de Animais|Ferim de Dedos c/...|           7500|     Atividades Veteri...|           Toledo-Pr|      Lesao Imediata|               Punho|Masculino|       T√≠pico|              Roraima|                 Paran√°|     1986-07-04|      2023-05-01|\n",
      "|    Chao - Superficie...|              2023-04-29|Viveirista Florestal|Frat dos Ossos Na...|            210|     Producao Floresta...|          Moji-Gua√ßu|             Fratura|Nariz (Inclusive ...|Masculino|       T√≠pico|             Maranh√£o|              S√£o Paulo|     1998-11-03|      2023-05-01|\n",
      "|         Serra - Maquina|              2023-04-28|          Desossador|Ferim de Dedos c/...|           1012|     Abate de Suinos, ...|      Bra√ßo do Norte|Amputacao ou Enuc...|                Dedo|Masculino|       T√≠pico|     N√£o identificado|         Santa Catarina|     1981-12-30|      2023-05-01|\n",
      "|    Superficie e Estr...|              2023-04-27|   Servente de Obras|Frat de Outr Osso...|           4330|      Obras de Acabamento|             Mar√≠lia|             Fratura|Mao (Exceto Punho...|Masculino|       T√≠pico|             Maranh√£o|              S√£o Paulo|     1982-11-03|      2023-05-01|\n",
      "|    Aprision. Em, Sob...|              2023-04-26|Oper. Centro de U...|Amput Traum de Um...|           2539|     Servicos de Usina...|             Itapira|Corte, Laceracao,...|                Dedo|Masculino|       T√≠pico|             Maranh√£o|              S√£o Paulo|     1987-09-02|      2023-05-01|\n",
      "+------------------------+------------------------+--------------------+--------------------+---------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------+---------------------+-----------------------+---------------+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SilverToGold\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "POSTGRES_HOST = \"localhost\"\n",
    "POSTGRES_PORT = \"5432\"\n",
    "POSTGRES_DB = \"cat_db\"\n",
    "POSTGRES_USER = \"admin\"\n",
    "POSTGRES_PASSWORD = \"admin\"\n",
    "\n",
    "conn_params = {\n",
    "    \"host\": POSTGRES_HOST,\n",
    "    \"database\": POSTGRES_DB,\n",
    "    \"user\": POSTGRES_USER,\n",
    "    \"password\": POSTGRES_PASSWORD,\n",
    "    \"port\": POSTGRES_PORT\n",
    "}\n",
    "\n",
    "connection_properties = {\n",
    "    \"user\": POSTGRES_USER,\n",
    "    \"password\": POSTGRES_PASSWORD,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    \n",
    "    query = \"SELECT * FROM ACIDENTE\"\n",
    "    \n",
    "    pdf = pd.read_sql(query, conn)\n",
    "    df_silver = spark.createDataFrame(pdf)\n",
    "    \n",
    "    print(\"Dados da camada Silver carregados\")\n",
    "    df_silver.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro na leitura: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        \n",
    "GOLD_SCHEMA = \"gold\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc6e0d",
   "metadata": {},
   "source": [
    "### Fun√ß√£o Gen√©rica de Carga de Dimens√µes\n",
    "\n",
    "Esta fun√ß√£o padroniza o processo de carga das dimens√µes, garantindo:\n",
    "- remo√ß√£o de duplicidades\n",
    "- preserva√ß√£o da business key\n",
    "- inser√ß√£o no schema Gold\n",
    "- valida√ß√£o b√°sica p√≥s-carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffaef169-d02d-4f57-858c-d8bb615969a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dim_with_psycopg2(table_name, pg_conn_params, spark):\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "    with psycopg2.connect(**pg_conn_params) as conn:\n",
    "        pdf = pd.read_sql(query, conn)\n",
    "\n",
    "    df_dim_loaded = spark.createDataFrame(pdf)\n",
    "    return df_dim_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4871cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dimension(\n",
    "    df_dim,\n",
    "    dim_name,\n",
    "    id_col_silver,\n",
    "    other_cols,\n",
    "    pg_conn_params,\n",
    "    cols_to_drop=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Salva dados em uma dimens√£o no PostgreSQL usando psycopg2,\n",
    "    preservando a business key.\n",
    "    Retorna um DataFrame Spark da dimens√£o carregada (com surrogate keys).\n",
    "    \"\"\"\n",
    "\n",
    "    table_name = f\"{GOLD_SCHEMA}.dim_{dim_name}\"\n",
    "    business_key_col = f\"chv_{dim_name}_org\"\n",
    "\n",
    "    # Prepara√ß√£o da dimens√£o no Spark\n",
    "    df_dim_unique = (\n",
    "        df_dim\n",
    "        .select(col(id_col_silver).alias(business_key_col), *other_cols)\n",
    "        .distinct()\n",
    "        .dropna(subset=[business_key_col])\n",
    "    )\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_dim_unique = df_dim_unique.drop(*cols_to_drop)\n",
    "\n",
    "    print(f\"\\n---> Criando e carregando Dimens√£o: {table_name}\")\n",
    "    count_unique = df_dim_unique.count()\n",
    "    print(f\"     Registros √∫nicos: {count_unique}\")\n",
    "\n",
    "    if count_unique == 0:\n",
    "        print(\"DataFrame vazio\")\n",
    "        return None\n",
    "\n",
    "    # Converter para Pandas para inser√ß√£o via psycopg2\n",
    "    pdf = df_dim_unique.toPandas()\n",
    "\n",
    "    columns = list(pdf.columns)\n",
    "    cols_sql = \", \".join(columns)\n",
    "    values_sql = \", \".join([f\"%({c})s\" for c in columns])\n",
    "\n",
    "    insert_sql = f\"\"\"\n",
    "        INSERT INTO {table_name} ({cols_sql})\n",
    "        VALUES ({values_sql})\n",
    "        ON CONFLICT ({business_key_col}) DO NOTHING\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Conex√£o PostgreSQL\n",
    "        with psycopg2.connect(**pg_conn_params) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                execute_batch(\n",
    "                    cur,\n",
    "                    insert_sql,\n",
    "                    pdf.to_dict(orient=\"records\"),\n",
    "                    page_size=1000\n",
    "                )\n",
    "            conn.commit()\n",
    "\n",
    "        print(\"Inser√ß√£o conclu√≠da\")\n",
    "\n",
    "        # Recarregar dimens√£o com surrogate keys via Spark\n",
    "        df_dim_loaded = load_dim_with_psycopg2(\n",
    "            table_name=table_name,\n",
    "            pg_conn_params=pg_conn_params,\n",
    "            spark=spark\n",
    "        )\n",
    "\n",
    "\n",
    "        count_check = df_dim_loaded.count()\n",
    "\n",
    "        if count_check >= count_unique:\n",
    "            print(f\"Dimens√£o carregada. Registros confirmados: {count_check}\")\n",
    "        else:\n",
    "            print(f\"Confirmados ({count_check}) < esperados ({count_unique})\")\n",
    "\n",
    "        return df_dim_loaded\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gravar dimens√£o {table_name}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9a9a6",
   "metadata": {},
   "source": [
    "### Dimens√£o Tempo\n",
    "\n",
    "A dimens√£o tempo √© utilizada para:\n",
    "- data do acidente\n",
    "- data de emiss√£o da CAT\n",
    "- data de nascimento do trabalhador\n",
    "\n",
    "Ela permite an√°lises temporais como sazonalidade, tend√™ncias e compara√ß√µes anuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97362879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_tempo(df_silver):    \n",
    "    df_datas = df_silver.select(\"data_acidente_referencia\").distinct() \\\n",
    "        .union(df_silver.select(\"data_emissao_cat\").distinct()) \\\n",
    "        .union(df_silver.select(\"data_nascimento\").distinct()) \\\n",
    "        .withColumnRenamed(\"data_acidente_referencia\", \"data\") \\\n",
    "        .distinct() \\\n",
    "        .dropna()\n",
    "    \n",
    "    df_tempo = df_datas.select(\n",
    "        col(\"data\"),\n",
    "        dayofmonth(\"data\").alias(\"dia\"),\n",
    "        month(\"data\").alias(\"mes\"),\n",
    "        date_format(\"data\", \"MMMM\").alias(\"nome_mes\"),\n",
    "        quarter(\"data\").alias(\"trimestre\"),\n",
    "        year(\"data\").alias(\"ano\"),\n",
    "        dayofweek(\"data\").alias(\"dia_semana\"),\n",
    "        when(dayofweek(\"data\").isin(1, 7), True).otherwise(False).alias(\"is_fim_semana\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_tempo,\n",
    "        \"tempo\",\n",
    "        \"data\",\n",
    "        [\"dia\", \"mes\", \"nome_mes\", \"trimestre\", \"ano\", \"dia_semana\", \"is_fim_semana\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d636630",
   "metadata": {},
   "source": [
    "### Dimens√£o Trabalhador\n",
    "\n",
    "Representa caracter√≠sticas demogr√°ficas e ocupacionais do trabalhador\n",
    "no momento do acidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_trabalhador(df_silver):\n",
    "    df_trabalhador = df_silver.select(\n",
    "        concat_ws(\"_\", \n",
    "                  upper(trim(col(\"sexo\"))),\n",
    "                  col(\"cbo_codigo_descricao\"),\n",
    "                  col(\"data_nascimento\")\n",
    "        ).alias(\"id_trabalhador\"),\n",
    "        upper(trim(col(\"sexo\"))).alias(\"sexo\"),\n",
    "        col(\"cbo_codigo_descricao\").alias(\"fk_cbo\"),\n",
    "        col(\"data_nascimento\").alias(\"fk_tempo_nascimento\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_trabalhador,\n",
    "        \"trabalhador\",\n",
    "        \"id_trabalhador\",\n",
    "        [\"sexo\", \"fk_cbo\", \"fk_tempo_nascimento\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e7142",
   "metadata": {},
   "source": [
    "### Dimens√£o Empregador\n",
    "\n",
    "A dimens√£o empregador representa as caracter√≠sticas da empresa\n",
    "respons√°vel pelo v√≠nculo de trabalho no momento do acidente.\n",
    "\n",
    "Esta dimens√£o referencia:\n",
    "- a dimens√£o CNAE (atividade econ√¥mica)\n",
    "- a dimens√£o Munic√≠pio (localiza√ß√£o do empregador)\n",
    "\n",
    "Sua cria√ß√£o ocorre ap√≥s a carga das dimens√µes independentes,\n",
    "garantindo integridade referencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fab3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_empregador(df_silver):\n",
    "    df_empregador = df_silver.select(\n",
    "        concat_ws(\"_\", \n",
    "                  col(\"cnae_empregador\"),\n",
    "                  col(\"municipio_empregador\")\n",
    "        ).alias(\"id_empregador\"),\n",
    "        col(\"cnae_empregador\").alias(\"fk_cnae\"),\n",
    "        col(\"municipio_empregador\").alias(\"fk_municipio\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_empregador,\n",
    "        \"empregador\",\n",
    "        \"id_empregador\",\n",
    "        [\"fk_cnae\", \"fk_municipio\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7ebba",
   "metadata": {},
   "source": [
    "### Dimens√µes de Classifica√ß√£o\n",
    "\n",
    "As dimens√µes a seguir representam classifica√ß√µes oficiais utilizadas\n",
    "para padroniza√ß√£o e an√°lise estat√≠stica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa325a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_cbo(df_silver):\n",
    "    df_cbo = df_silver.select(\n",
    "        col(\"cbo_codigo_descricao\").alias(\"id_cbo\"),\n",
    "        col(\"cbo_codigo_descricao\").alias(\"codigo\"),\n",
    "        col(\"cbo_codigo_descricao\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cbo,\n",
    "        \"cbo\",\n",
    "        \"id_cbo\",\n",
    "        [\"codigo\", \"descricao\"],\n",
    "        conn_params\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dim_cnae(df_silver):\n",
    "    df_cnae = df_silver.select(\n",
    "        col(\"cnae_empregador\").alias(\"id_cnae\"),\n",
    "        col(\"cnae_empregador\").alias(\"codigo\"),\n",
    "        col(\"cnae_empregador_descricao\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cnae,\n",
    "        \"cnae\",\n",
    "        \"id_cnae\",\n",
    "        [\"codigo\", \"descricao\"],\n",
    "        conn_params\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dim_cid10(df_silver):\n",
    "    df_cid = df_silver.select(\n",
    "        col(\"cid_10\").alias(\"id_cid10\"),\n",
    "        col(\"cid_10\").alias(\"codigo\"),\n",
    "        col(\"cid_10\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cid,\n",
    "        \"cid10\",\n",
    "        \"id_cid10\",\n",
    "        [\"codigo\", \"descricao\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfc0b7",
   "metadata": {},
   "source": [
    "### Dimens√£o Munic√≠pio\n",
    "\n",
    "A dimens√£o munic√≠pio √© utilizada para:\n",
    "- local do acidente\n",
    "- local do empregador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8f1f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_municipio(df_silver):\n",
    "    df_mun_acidente = df_silver.select(\n",
    "        col(\"uf_municipio_acidente\").alias(\"codigo_ibge\"),\n",
    "        col(\"uf_municipio_acidente\").alias(\"nome\"),\n",
    "        col(\"uf_municipio_acidente\").alias(\"uf\")\n",
    "    )\n",
    "    \n",
    "    df_mun_empregador = df_silver.select(\n",
    "        col(\"municipio_empregador\").alias(\"codigo_ibge\"),\n",
    "        col(\"municipio_empregador\").alias(\"nome\"),\n",
    "        col(\"uf_municipio_empregador\").alias(\"uf\")\n",
    "    )\n",
    "    \n",
    "    df_municipio = df_mun_acidente.union(df_mun_empregador) \\\n",
    "        .distinct() \\\n",
    "        .dropna(subset=[\"codigo_ibge\"])\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_municipio,\n",
    "        \"municipio\",\n",
    "        \"codigo_ibge\",\n",
    "        [\"nome\", \"uf\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003ff7f",
   "metadata": {},
   "source": [
    "### Dimens√µes de Caracteriza√ß√£o do Acidente\n",
    "\n",
    "Estas dimens√µes descrevem o contexto e as causas do acidente de trabalho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f16d4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_tipo_acidente(df_silver):    \n",
    "    df_tipo_acidente = df_silver.select(\n",
    "        col(\"tipo_acidente\").alias(\"id_tipo_acidente\"),\n",
    "        col(\"tipo_acidente\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_tipo_acidente,\n",
    "        \"tipo_acidente\",\n",
    "        \"id_tipo_acidente\",\n",
    "        [\"descricao\"],\n",
    "        conn_params\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dim_lesao(df_silver):\n",
    "    df_lesao = df_silver.select(\n",
    "        concat_ws(\"_\", \n",
    "                  col(\"natureza_lesao\"), \n",
    "                  col(\"parte_corpo_atingida\")\n",
    "        ).alias(\"id_lesao\"),\n",
    "        col(\"natureza_lesao\").alias(\"natureza_lesao\"),\n",
    "        col(\"parte_corpo_atingida\").alias(\"parte_corpo_atingida\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_lesao,\n",
    "        \"lesao\",\n",
    "        \"id_lesao\",\n",
    "        [\"natureza_lesao\", \"parte_corpo_atingida\"],\n",
    "        conn_params\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dim_agente_causador(df_silver):\n",
    "    df_agente = df_silver.select(\n",
    "        col(\"agente_causador_acidente\").alias(\"id_agente_causador\"),\n",
    "        col(\"agente_causador_acidente\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_agente,\n",
    "        \"agente_causador\",\n",
    "        \"id_agente_causador\",\n",
    "        [\"descricao\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e3256",
   "metadata": {},
   "source": [
    "## Execu√ß√£o da Carga das Dimens√µes\n",
    "\n",
    "Nesta etapa √© executado o processo completo de cria√ß√£o e carga das dimens√µes,\n",
    "respeitando a ordem de depend√™ncia entre elas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0897f02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CARGA DAS DIMENS√ïES - STAR SCHEMA\n",
      "============================================================\n",
      "\n",
      "üìÖ Criando Dimens√£o Tempo\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_tempo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:06 WARN TaskSetManager: Stage 1 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:10 WARN TaskSetManager: Stage 2 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:11 WARN TaskSetManager: Stage 3 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:15 WARN TaskSetManager: Stage 13 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 18083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:16 WARN TaskSetManager: Stage 14 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:17 WARN TaskSetManager: Stage 15 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√£o carregada. Registros confirmados: 18083\n",
      "\n",
      "üß† Criando Dimens√£o CBO\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_cbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:25 WARN TaskSetManager: Stage 23 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:27 WARN TaskSetManager: Stage 29 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√£o carregada. Registros confirmados: 1647\n",
      "\n",
      "üìç Criando Dimens√£o Munic√≠pio\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_municipio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:30 WARN TaskSetManager: Stage 35 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:34 WARN TaskSetManager: Stage 41 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmados (3304) < esperados (3311)\n",
      "\n",
      "üè¢ Criando Dimens√£o CNAE\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_cnae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:38 WARN TaskSetManager: Stage 47 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:40 WARN TaskSetManager: Stage 53 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n",
      "Dimens√£o carregada. Registros confirmados: 663\n",
      "\n",
      "‚ö†Ô∏è Criando Dimens√£o Tipo de Acidente\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_tipo_acidente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:42 WARN TaskSetManager: Stage 59 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:44 WARN TaskSetManager: Stage 65 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n",
      "Dimens√£o carregada. Registros confirmados: 3\n",
      "\n",
      "ü©∫ Criando Dimens√£o Les√£o\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_lesao\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:46 WARN TaskSetManager: Stage 71 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:48 WARN TaskSetManager: Stage 77 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n",
      "Dimens√£o carregada. Registros confirmados: 852\n",
      "\n",
      "üîß Criando Dimens√£o Agente Causador\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_agente_causador\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:50 WARN TaskSetManager: Stage 83 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:52 WARN TaskSetManager: Stage 89 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√£o carregada. Registros confirmados: 296\n",
      "\n",
      "üß¨ Criando Dimens√£o CID-10\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_cid10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:54 WARN TaskSetManager: Stage 95 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:15:56 WARN TaskSetManager: Stage 101 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√£o carregada. Registros confirmados: 1916\n",
      "\n",
      "üë§ Criando Dimens√£o Trabalhador\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_trabalhador\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:15:58 WARN TaskSetManager: Stage 107 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:16:04 WARN TaskSetManager: Stage 113 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 132473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n",
      "26/01/17 15:16:27 WARN TaskSetManager: Stage 116 contains a task of very large size (1526 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√£o carregada. Registros confirmados: 132473\n",
      "\n",
      "üè≠ Criando Dimens√£o Empregador\n",
      "\n",
      "---> Criando e carregando Dimens√£o: gold.dim_empregador\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:16:28 WARN TaskSetManager: Stage 119 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:16:30 WARN TaskSetManager: Stage 125 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros √∫nicos: 39659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inser√ß√£o conclu√≠da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24707/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√£o carregada. Registros confirmados: 39659\n",
      "\n",
      "============================================================\n",
      "DIMENS√ïES FORAM CARREGADAS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dim_tempo = create_dim_tempo(df_silver)          \n",
    "    dim_cbo = create_dim_cbo(df_silver)            \n",
    "    dim_municipio = create_dim_municipio(df_silver)      \n",
    "    dim_cnae = create_dim_cnae(df_silver)           \n",
    "    dim_tipo_acidente = create_dim_tipo_acidente(df_silver)  \n",
    "    dim_lesao = create_dim_lesao(df_silver)          \n",
    "    dim_agente_causador = create_dim_agente_causador(df_silver)\n",
    "    dim_cid10 = create_dim_cid10(df_silver)          \n",
    "\n",
    "    dim_trabalhador = create_dim_trabalhador(df_silver)\n",
    "    dim_empregador = create_dim_empregador(df_silver)\n",
    "        \n",
    "    print(\"Dimens√µes foram carregadas\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nERRO NA CARGA DAS DIMENS√ïES: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5dbab",
   "metadata": {},
   "source": [
    "### Preparando dados da camada Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "661cdb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:16:37 WARN TaskSetManager: Stage 131 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 131:==========================================>              (6 + 2) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros preparados: 291776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_base = df_silver.select(\n",
    "    concat_ws(\"_\",\n",
    "        col(\"data_acidente_referencia\"),\n",
    "        col(\"sexo\"),\n",
    "        col(\"cbo_codigo_descricao\"),\n",
    "        col(\"cnae_empregador\"),\n",
    "        col(\"municipio_empregador\")\n",
    "    ).alias(\"id_cat\"),\n",
    "    \n",
    "    col(\"data_acidente_referencia\").alias(\"data_acidente\"),\n",
    "    col(\"data_emissao_cat\").alias(\"data_emissao\"),\n",
    "    col(\"data_nascimento\"),\n",
    "    \n",
    "    concat_ws(\"_\", \n",
    "        upper(trim(col(\"sexo\"))),\n",
    "        col(\"cbo_codigo_descricao\"),\n",
    "        col(\"data_nascimento\")\n",
    "    ).alias(\"id_trabalhador\"),\n",
    "    \n",
    "    col(\"cbo_codigo_descricao\").alias(\"codigo_cbo\"),\n",
    "    \n",
    "    concat_ws(\"_\", \n",
    "        col(\"cnae_empregador\"),\n",
    "        col(\"municipio_empregador\")\n",
    "    ).alias(\"id_empregador\"),\n",
    "    \n",
    "    col(\"cnae_empregador\").alias(\"codigo_cnae\"),\n",
    "    \n",
    "    col(\"uf_municipio_acidente\").alias(\"codigo_municipio_acidente\"),\n",
    "    col(\"municipio_empregador\").alias(\"codigo_municipio_empregador\"),\n",
    "    \n",
    "    col(\"tipo_acidente\").alias(\"codigo_tipo_acidente\"),\n",
    "    col(\"natureza_lesao\").alias(\"codigo_natureza_lesao\"),\n",
    "    col(\"parte_corpo_atingida\").alias(\"codigo_parte_corpo\"),\n",
    "    col(\"agente_causador_acidente\").alias(\"codigo_agente_causador\"),\n",
    "    col(\"cid_10\").alias(\"codigo_cid10\"),\n",
    "    \n",
    "    (year(col(\"data_acidente_referencia\")) - year(col(\"data_nascimento\"))).cast(IntegerType()).alias(\"idade_trabalhador\"),\n",
    "    \n",
    "    when(col(\"tipo_acidente\").like(\"%trajeto%\"), 1).otherwise(0).alias(\"flag_trajeto\")\n",
    ")\n",
    "\n",
    "print(f\"Registros preparados: {df_base.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e713af6-7415-4587-8e31-4d021e2111df",
   "metadata": {},
   "source": [
    "## Lookup de Surrogate Keys\n",
    "\n",
    "Realiza joins (lookups) entre df_base e todas as dimens√µes\n",
    "para substituir business keys por surrogate keys (FKs).\n",
    "\n",
    "- Trocar valores de neg√≥cio por IDs t√©cnicos (surrogate keys)\n",
    "- Criar relacionamentos entre fato e dimens√µes\n",
    "- Preparar estrutura final da tabela fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "274d1746-9fe4-4888-87b2-caca064c0eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [1/14] dim_tempo -> data_acidente\n",
      "     [2/14] dim_tempo -> data_emissao\n",
      "     [3/14] dim_tempo -> data_nascimento\n",
      "     [4/14] dim_trabalhador\n",
      "     [5/14] dim_cbo\n",
      "     [6/14] dim_empregador\n",
      "     [7/14] dim_cnae\n",
      "     [8/14] dim_municipio -> acidente\n",
      "     [9/14] dim_municipio -> empregador\n",
      "     [10/14] dim_tipo_acidente\n",
      "     [11/14] dim_lesao\n",
      "     [12/14] dim_agente_causador\n",
      "     [13/14] dim_cid10\n",
      "     [14/14] Lookups conclu√≠dos!\n"
     ]
    }
   ],
   "source": [
    "df_fact = df_base.join(\n",
    "    dim_tempo.select(\n",
    "        col(\"id_tempo\").alias(\"fk_tempo_acidente\"),\n",
    "        col(\"chv_tempo_org\").alias(\"data_join_acidente\")\n",
    "    ),\n",
    "    df_base.data_acidente == col(\"data_join_acidente\"),\n",
    "    \"left\"\n",
    ").drop(\"data_join_acidente\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_tempo.select(\n",
    "        col(\"id_tempo\").alias(\"fk_tempo_emissao\"),\n",
    "        col(\"chv_tempo_org\").alias(\"data_join_emissao\")\n",
    "    ),\n",
    "    df_fact.data_emissao == col(\"data_join_emissao\"),\n",
    "    \"left\"\n",
    ").drop(\"data_join_emissao\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_tempo.select(\n",
    "        col(\"id_tempo\").alias(\"fk_tempo_nascimento\"),\n",
    "        col(\"chv_tempo_org\").alias(\"data_join_nascimento\")\n",
    "    ),\n",
    "    df_fact.data_nascimento == col(\"data_join_nascimento\"),\n",
    "    \"left\"\n",
    ").drop(\"data_join_nascimento\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_trabalhador.select(\n",
    "        col(\"id_trabalhador\").alias(\"fk_trabalhador\"),\n",
    "        col(\"chv_trabalhador_org\").alias(\"id_trab_join\")\n",
    "    ),\n",
    "    df_fact.id_trabalhador == col(\"id_trab_join\"),\n",
    "    \"left\"\n",
    ").drop(\"id_trab_join\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_cbo.select(\n",
    "        col(\"id_cbo\").alias(\"fk_cbo\"),\n",
    "        col(\"chv_cbo_org\").alias(\"codigo_cbo_join\")\n",
    "    ),\n",
    "    df_fact.codigo_cbo == col(\"codigo_cbo_join\"),\n",
    "    \"left\"\n",
    ").drop(\"codigo_cbo_join\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_empregador.select(\n",
    "        col(\"id_empregador\").alias(\"fk_empregador\"),\n",
    "        col(\"chv_empregador_org\").alias(\"id_emp_join\")\n",
    "    ),\n",
    "    df_fact.id_empregador == col(\"id_emp_join\"),\n",
    "    \"left\"\n",
    ").drop(\"id_emp_join\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_cnae.select(\n",
    "        col(\"id_cnae\").alias(\"fk_cnae\"),\n",
    "        col(\"chv_cnae_org\").alias(\"codigo_cnae_join\")\n",
    "    ),\n",
    "    df_fact.codigo_cnae == col(\"codigo_cnae_join\"),\n",
    "    \"left\"\n",
    ").drop(\"codigo_cnae_join\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_municipio.select(\n",
    "        col(\"id_municipio\").alias(\"fk_municipio_acidente\"),\n",
    "        col(\"chv_municipio_org\").alias(\"mun_acidente_join\")\n",
    "    ),\n",
    "    df_fact.codigo_municipio_acidente == col(\"mun_acidente_join\"),\n",
    "    \"left\"\n",
    ").drop(\"mun_acidente_join\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_municipio.select(\n",
    "        col(\"id_municipio\").alias(\"fk_municipio_empregador\"),\n",
    "        col(\"chv_municipio_org\").alias(\"mun_empregador_join\")\n",
    "    ),\n",
    "    df_fact.codigo_municipio_empregador == col(\"mun_empregador_join\"),\n",
    "    \"left\"\n",
    ").drop(\"mun_empregador_join\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_tipo_acidente.select(\n",
    "        col(\"id_tipo_acidente\").alias(\"fk_tipo_acidente\"),\n",
    "        col(\"chv_tipo_acidente_org\").alias(\"tipo_acidente_join\")\n",
    "    ),\n",
    "    df_fact.codigo_tipo_acidente == col(\"tipo_acidente_join\"),\n",
    "    \"left\"\n",
    ").drop(\"tipo_acidente_join\")\n",
    "\n",
    "df_fact = df_fact.withColumn(\n",
    "    \"lesao_join_key\",\n",
    "    concat_ws(\"_\", col(\"codigo_natureza_lesao\"), col(\"codigo_parte_corpo\"))\n",
    ")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_lesao.select(\n",
    "        col(\"id_lesao\").alias(\"fk_lesao\"),\n",
    "        col(\"chv_lesao_org\").alias(\"lesao_join\")\n",
    "    ),\n",
    "    df_fact.lesao_join_key == col(\"lesao_join\"),\n",
    "    \"left\"\n",
    ").drop(\"lesao_join\", \"lesao_join_key\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_agente_causador.select(\n",
    "        col(\"id_agente_causador\").alias(\"fk_agente_causador\"),\n",
    "        col(\"chv_agente_causador_org\").alias(\"agente_join\")\n",
    "    ),\n",
    "    df_fact.codigo_agente_causador == col(\"agente_join\"),\n",
    "    \"left\"\n",
    ").drop(\"agente_join\")\n",
    "\n",
    "df_fact = df_fact.join(\n",
    "    dim_cid10.select(\n",
    "        col(\"id_cid10\").alias(\"fk_cid10\"),\n",
    "        col(\"chv_cid10_org\").alias(\"cid_join\")\n",
    "    ),\n",
    "    df_fact.codigo_cid10 == col(\"cid_join\"),\n",
    "    \"left\"\n",
    ").drop(\"cid_join\")\n",
    "\n",
    "print(\"Lookups conclu√≠dos!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c31259",
   "metadata": {},
   "source": [
    "## Montagem da Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd4226f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:29:24 WARN TaskSetManager: Stage 136 contains a task of very large size (1526 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:29:26 WARN TaskSetManager: Stage 144 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 169:>                                                        (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros na tabela fato: 145870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_fact_final = df_fact.select(\n",
    "    col(\"id_cat\").alias(\"chv_cat_org\"),\n",
    "    \n",
    "    \"fk_tempo_acidente\",\n",
    "    \"fk_tempo_emissao\",\n",
    "    \"fk_tempo_nascimento\",\n",
    "    \n",
    "    \"fk_trabalhador\",\n",
    "    \"fk_cbo\",\n",
    "    \"fk_empregador\",\n",
    "    \"fk_cnae\",\n",
    "    \n",
    "    \"fk_municipio_acidente\",\n",
    "    \"fk_municipio_empregador\",\n",
    "\n",
    "    \"fk_tipo_acidente\",\n",
    "    \"fk_lesao\",\n",
    "    \"fk_agente_causador\",\n",
    "    \"fk_cid10\",\n",
    "\n",
    "    \"idade_trabalhador\",\n",
    "\n",
    "    \"flag_trajeto\"\n",
    "    \n",
    ").distinct()\n",
    "\n",
    "count_fact = df_fact_final.count()\n",
    "print(f\"Registros na tabela fato: {count_fact}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab941368",
   "metadata": {},
   "source": [
    "### Carga da Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ec69d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas: 16\n",
      "Colunas a inserir: ['chv_cat_org', 'fk_tempo_acidente', 'fk_tempo_emissao', 'fk_tempo_nascimento', 'fk_trabalhador', 'fk_cbo', 'fk_empregador', 'fk_cnae', 'fk_municipio_acidente', 'fk_municipio_empregador', 'fk_tipo_acidente', 'fk_lesao', 'fk_agente_causador', 'fk_cid10', 'idade_trabalhador', 'flag_trajeto']\n",
      "\n",
      "Preparando dados para inser√ß√£o...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 15:30:09 WARN TaskSetManager: Stage 176 contains a task of very large size (1526 KiB). The maximum recommended task size is 1000 KiB.\n",
      "26/01/17 15:30:11 WARN TaskSetManager: Stage 181 contains a task of very large size (9331 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros a inserir: 145870\n",
      "\n",
      "üîå Estabelecendo conex√£o com PostgreSQL...\n",
      "üíæ Iniciando inser√ß√£o em lote usando execute_values...\n",
      "‚úÖ Carga de 145870 registros conclu√≠da com sucesso!\n",
      "\n",
      "üîç Validando carga...\n",
      "Registros confirmados no banco: 145870\n",
      "‚úÖ Valida√ß√£o conclu√≠da - carga bem-sucedida!\n",
      "\n",
      "üìà Estat√≠sticas da tabela fato:\n",
      "============================================================\n",
      "Total de Registros: 145870\n",
      "Total de Trabalhadores Distintos: 132473\n",
      "Total de Empregadores Distintos: 39659\n",
      "M√©dia Idade Trabalhador: 36.58\n",
      "Total Acidentes de Trajeto: 0\n",
      "============================================================\n",
      "\n",
      "üîå Conex√£o com PostgreSQL encerrada.\n"
     ]
    }
   ],
   "source": [
    "colunas = df_fact_final.columns\n",
    "fact_table_name = f\"{GOLD_SCHEMA}.fato_acidente_trabalho\"\n",
    "\n",
    "print(f\"Colunas: {len(colunas)}\")\n",
    "print(f\"Colunas a inserir: {colunas}\")\n",
    "print(f\"\\nPreparando dados para inser√ß√£o...\")\n",
    "\n",
    "dados_para_inserir = [tuple(row) for row in df_fact_final.collect()]\n",
    "\n",
    "conn = None\n",
    "cursor = None\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = f\"INSERT INTO {fact_table_name} ({', '.join(colunas)}) VALUES %s\"\n",
    "    \n",
    "    extras.execute_values(\n",
    "        cursor,\n",
    "        query,\n",
    "        dados_para_inserir,\n",
    "        template=None,\n",
    "        page_size=1000\n",
    "    )\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"Registros conclu√≠da com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Erro ao inserir dados: {e}\")\n",
    "    if conn:\n",
    "        conn.rollback()\n",
    "    raise e\n",
    "    \n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
