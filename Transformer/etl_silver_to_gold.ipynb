{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f69e7b82",
   "metadata": {},
   "source": [
    "# ETL (Extrair, Transformar e Carregar) da camada Silver para Gold.\n",
    "\n",
    "Este notebook realiza o processo de ETL para transformar e carregar os dados da camada Silver para a camada Gold no data lake. A camada Gold é otimizada para consultas analíticas e relatórios, garantindo que os dados estejam prontos para uso por ferramentas de BI e análise avançada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca037c69",
   "metadata": {},
   "source": [
    "### Configuração do Ambiente de Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ac6ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (4.1.1)\n",
      "Requirement already satisfied: py4j<0.10.9.10,>=0.10.9.7 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pyspark) (0.10.9.9)\n",
      "Requirement already satisfied: psycopg2 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (2.9.11)\n",
      "Requirement already satisfied: pandas in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pandas) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/yabamiah/Sandbox/cat-analytics/.venv/lib64/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install psycopg2\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ea172",
   "metadata": {},
   "source": [
    "# Criação e Carga das Dimensões (Star Schema)\n",
    "\n",
    "Esta seção tem como objetivo realizar a **criação e carga das tabelas dimensão**\n",
    "da camada Gold, seguindo o modelo **Star Schema**, a partir de dados previamente\n",
    "tratados na camada Silver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10d29f",
   "metadata": {},
   "source": [
    "### Importação de Bibliotecas\n",
    "\n",
    "Nesta seção são importadas as bibliotecas necessárias para:\n",
    "- manipulação de dados com PySpark\n",
    "- criação de colunas derivadas\n",
    "- conexão com o banco PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617b271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from psycopg2.extras import execute_batch\n",
    "from psycopg2 import extras\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, concat_ws, year, month, dayofmonth, quarter, \n",
    "    dayofweek, when, date_format, monotonically_increasing_id,\n",
    "    lit, trim, upper\n",
    ")\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.sql.types import StringType, IntegerType, DateType, DecimalType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647b0e7",
   "metadata": {},
   "source": [
    "### Configuração do Ambiente\n",
    "\n",
    "Nesta etapa são configurados:\n",
    "- a sessão Spark\n",
    "- a conexão JDBC com o PostgreSQL\n",
    "- o schema de destino da camada Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ca19e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/22 22:37:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/tmp/ipykernel_51658/3971848863.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados da camada Silver carregados\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):                                  (0 + 1) / 1]\n",
      "  File \"/home/yabamiah/Sandbox/cat-analytics/.venv/lib/python3.14/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "  File \"/home/yabamiah/Sandbox/cat-analytics/.venv/lib/python3.14/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+--------------------+--------------------+---------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------+---------------------+-----------------------+---------------+----------------+\n",
      "|agente_causador_acidente|data_acidente_referencia|cbo_codigo_descricao|              cid_10|cnae_empregador|cnae_empregador_descricao|municipio_empregador|      natureza_lesao|parte_corpo_atingida|     sexo|tipo_acidente|uf_municipio_acidente|uf_municipio_empregador|data_nascimento|data_emissao_cat|\n",
      "+------------------------+------------------------+--------------------+--------------------+---------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------+---------------------+-----------------------+---------------+----------------+\n",
      "|    Rua e Estrada - S...|              2023-03-27|       Administrador|   Frat da Clavicula|           4711|     Comercio Varejist...| São José dos Campos|             Fratura|               Ombro|Masculino|      Trajeto|             Maranhão|              São Paulo|     1977-06-05|      2023-05-01|\n",
      "|    Impacto de Pes. C...|              2023-04-30|  Tec. de Enfermagem|   Outr Locais Espec|           8610|     Atividades de Ate...|             Goiânia|  Outras Lesoes, Nic|                Dedo| Feminino|       Típico|     Não identificado|                  Goiás|     1992-08-08|      2023-05-01|\n",
      "|    Agente Infeccioso...|              2023-03-31|Analista de Desen...|Infecc p/Coronavi...|           8610|     Atividades de Ate...|        Porto Alegre|Doenca Contagiosa...|Aparelho Respirat...|Masculino|       Doença|     Não identificado|      Rio Grande do Sul|     1981-05-31|      2023-04-16|\n",
      "|    Chave de Porca ou...|              2023-04-15|    Inst. Tubulações|     Frat do Polegar|           4322|     Instalacoes Hidra...|           Araguaína|             Fratura|                Dedo|Masculino|       Típico|              Sergipe|              Tocantins|     1994-10-20|      2023-05-01|\n",
      "|    Rua e Estrada - S...|              2023-04-28|Oper. Máquina Cor...|Luxacao da Articu...|           2330|     Fabricacao de Art...|Campos dos Goytac...|             Luxacao|Tronco, Parte Mul...|Masculino|      Trajeto|            Tocantins|         Rio de Janeiro|     1993-08-21|      2023-05-01|\n",
      "|    Impacto Sofrido p...|              2023-04-27|Carpinteiro de Obras|Capsulite Adesiva...|           4120|     Construcao de Edi...|           São Paulo|      Lesao Imediata|               Ombro|Masculino|       Típico|             Maranhão|              São Paulo|     1972-05-30|      2023-05-01|\n",
      "|        Não identificado|              2023-04-22|  Tec. de Enfermagem|Contato Exposicao...|           8610|     Atividades de Ate...|       Caxias do Sul|Corte, Laceracao,...|                Dedo| Feminino|       Típico|     Não identificado|      Rio Grande do Sul|     1983-03-08|      2023-05-01|\n",
      "|    Impacto de Pes. C...|              2023-04-26|  Tec. de Enfermagem|   Contusao do Torax|           8610|     Atividades de Ate...|       Caxias do Sul|  Outras Lesoes, Nic|Partes Multiplas ...| Feminino|       Típico|     Não identificado|      Rio Grande do Sul|     1985-05-14|      2023-05-01|\n",
      "|    Impacto Sofrido p...|              2023-04-28|Alimentador de Li...|Ferim de Regiao N...|           1071|     Fabricacao de Acu...|         Igreja Nova|Amputacao ou Enuc...|                Dedo|Masculino|       Típico|     Não identificado|                Alagoas|     1992-01-03|      2023-05-01|\n",
      "|    Rua e Estrada - S...|              2023-04-13|Controlador de Pr...|Frat dos Ossos Na...|           4789|     Comercio Varejist...|Campos dos Goytac...|             Fratura|Nariz (Inclusive ...|Masculino|       Típico|            Tocantins|         Rio de Janeiro|     1976-10-13|      2023-05-01|\n",
      "|            Maquina, Nic|              2023-04-27|         Carpinteiro|Hemorragia Subara...|           4330|      Obras de Acabamento|           São Paulo|  Outras Lesoes, Nic|Cabeca, Partes Mu...|Masculino|       Típico|             Maranhão|              São Paulo|     1970-03-05|      2023-05-01|\n",
      "|    Veiculo Rodoviari...|              2023-04-26|        Coletor Lixo|           Dor Aguda|           3811|     Coleta de Residuo...|     Campo Grande-Ms|Contusao, Esmagam...|              Joelho|Masculino|       Típico|     Não identificado|     Mato Grosso do Sul|     2001-12-28|      2023-05-01|\n",
      "|    Veiculo Rodoviari...|              2023-04-26|        Coletor Lixo|Entorse e Distens...|           3811|     Coleta de Residuo...|     Campo Grande-Ms|   Distensao, Torcao|Articulacao do To...|Masculino|       Típico|     Não identificado|     Mato Grosso do Sul|     1996-07-24|      2023-05-01|\n",
      "|    Impacto de Pes. C...|              2023-04-26|    Não identificado|Contusao de Outr ...|           8511|     Educacao Infantil...|               Betim|Contusao, Esmagam...|Pe (Exceto Artelhos)| Feminino|       Típico|             Rondônia|           Minas Gerais|     1988-05-29|      2023-05-01|\n",
      "|    Impacto de Pes. C...|              2023-04-06|Motorista de Cami...|Traum Musc Flexor...|           4930|     Transporte Rodovi...|           São Paulo|             Luxacao|Braco (Entre O Pu...|Masculino|       Típico|             Maranhão|              São Paulo|     1978-01-23|      2023-05-01|\n",
      "|    Ataque de Ser Viv...|              2023-04-11| Tratador de Animais|Ferim de Dedos c/...|           7500|     Atividades Veteri...|           Toledo-Pr|      Lesao Imediata|               Punho|Masculino|       Típico|              Roraima|                 Paraná|     1986-07-04|      2023-05-01|\n",
      "|    Chao - Superficie...|              2023-04-29|Viveirista Florestal|Frat dos Ossos Na...|            210|     Producao Floresta...|          Moji-Guaçu|             Fratura|Nariz (Inclusive ...|Masculino|       Típico|             Maranhão|              São Paulo|     1998-11-03|      2023-05-01|\n",
      "|         Serra - Maquina|              2023-04-28|          Desossador|Ferim de Dedos c/...|           1012|     Abate de Suinos, ...|      Braço do Norte|Amputacao ou Enuc...|                Dedo|Masculino|       Típico|     Não identificado|         Santa Catarina|     1981-12-30|      2023-05-01|\n",
      "|    Superficie e Estr...|              2023-04-27|   Servente de Obras|Frat de Outr Osso...|           4330|      Obras de Acabamento|             Marília|             Fratura|Mao (Exceto Punho...|Masculino|       Típico|             Maranhão|              São Paulo|     1982-11-03|      2023-05-01|\n",
      "|    Aprision. Em, Sob...|              2023-04-26|Oper. Centro de U...|Amput Traum de Um...|           2539|     Servicos de Usina...|             Itapira|Corte, Laceracao,...|                Dedo|Masculino|       Típico|             Maranhão|              São Paulo|     1987-09-02|      2023-05-01|\n",
      "+------------------------+------------------------+--------------------+--------------------+---------------+-------------------------+--------------------+--------------------+--------------------+---------+-------------+---------------------+-----------------------+---------------+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SilverToGold\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "\n",
    "POSTGRES_HOST = \"localhost\"\n",
    "POSTGRES_PORT = \"5432\"\n",
    "POSTGRES_DB = \"cat_db\"\n",
    "POSTGRES_USER = \"admin\"\n",
    "POSTGRES_PASSWORD = \"admin\"\n",
    "\n",
    "conn_params = {\n",
    "    \"host\": POSTGRES_HOST,\n",
    "    \"database\": POSTGRES_DB,\n",
    "    \"user\": POSTGRES_USER,\n",
    "    \"password\": POSTGRES_PASSWORD,\n",
    "    \"port\": POSTGRES_PORT\n",
    "}\n",
    "\n",
    "connection_properties = {\n",
    "    \"user\": POSTGRES_USER,\n",
    "    \"password\": POSTGRES_PASSWORD,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    \n",
    "    query = \"SELECT * FROM ACIDENTE\"\n",
    "    \n",
    "    pdf = pd.read_sql(query, conn)\n",
    "    df_silver = spark.createDataFrame(pdf)\n",
    "    \n",
    "    print(\"Dados da camada Silver carregados\")\n",
    "    df_silver.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro na leitura: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        \n",
    "GOLD_SCHEMA = \"gold\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc6e0d",
   "metadata": {},
   "source": [
    "### Função Genérica de Carga de Dimensões\n",
    "\n",
    "Esta função padroniza o processo de carga das dimensões, garantindo:\n",
    "- remoção de duplicidades\n",
    "- preservação da business key\n",
    "- inserção no schema Gold\n",
    "- validação básica pós-carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffaef169-d02d-4f57-858c-d8bb615969a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dim_with_psycopg2(table_name, pg_conn_params, spark):\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "    with psycopg2.connect(**pg_conn_params) as conn:\n",
    "        pdf = pd.read_sql(query, conn)\n",
    "\n",
    "    df_dim_loaded = spark.createDataFrame(pdf)\n",
    "    return df_dim_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4871cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dimension(\n",
    "    df_dim,\n",
    "    dim_name,\n",
    "    id_col_silver,\n",
    "    other_cols,\n",
    "    pg_conn_params,\n",
    "    cols_to_drop=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Salva dados em uma dimensão no PostgreSQL usando psycopg2,\n",
    "    preservando a business key.\n",
    "    Retorna um DataFrame Spark da dimensão carregada (com surrogate keys).\n",
    "    \"\"\"\n",
    "\n",
    "    table_name = f\"{GOLD_SCHEMA}.dim_{dim_name}\"\n",
    "    business_key_col = f\"chv_{dim_name}_org\"\n",
    "\n",
    "    # Preparação da dimensão no Spark\n",
    "    df_dim_unique = (\n",
    "        df_dim\n",
    "        .select(col(id_col_silver).alias(business_key_col), *other_cols)\n",
    "        .distinct()\n",
    "        .dropna(subset=[business_key_col])\n",
    "    )\n",
    "\n",
    "    if cols_to_drop:\n",
    "        df_dim_unique = df_dim_unique.drop(*cols_to_drop)\n",
    "\n",
    "    print(f\"\\n---> Criando e carregando Dimensão: {table_name}\")\n",
    "    count_unique = df_dim_unique.count()\n",
    "    print(f\"     Registros únicos: {count_unique}\")\n",
    "\n",
    "    if count_unique == 0:\n",
    "        print(\"DataFrame vazio\")\n",
    "        return None\n",
    "\n",
    "    # Converter para Pandas para inserção via psycopg2\n",
    "    pdf = df_dim_unique.toPandas()\n",
    "\n",
    "    columns = list(pdf.columns)\n",
    "    cols_sql = \", \".join(columns)\n",
    "    values_sql = \", \".join([f\"%({c})s\" for c in columns])\n",
    "\n",
    "    insert_sql = f\"\"\"\n",
    "        INSERT INTO {table_name} ({cols_sql})\n",
    "        VALUES ({values_sql})\n",
    "        ON CONFLICT ({business_key_col}) DO NOTHING\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Conexão PostgreSQL\n",
    "        with psycopg2.connect(**pg_conn_params) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                execute_batch(\n",
    "                    cur,\n",
    "                    insert_sql,\n",
    "                    pdf.to_dict(orient=\"records\"),\n",
    "                    page_size=1000\n",
    "                )\n",
    "            conn.commit()\n",
    "\n",
    "        print(\"Inserção concluída\")\n",
    "\n",
    "        # Recarregar dimensão com surrogate keys via Spark\n",
    "        df_dim_loaded = load_dim_with_psycopg2(\n",
    "            table_name=table_name,\n",
    "            pg_conn_params=pg_conn_params,\n",
    "            spark=spark\n",
    "        )\n",
    "\n",
    "\n",
    "        count_check = df_dim_loaded.count()\n",
    "\n",
    "        if count_check >= count_unique:\n",
    "            print(f\"Dimensão carregada. Registros confirmados: {count_check}\")\n",
    "        else:\n",
    "            print(f\"Confirmados ({count_check}) < esperados ({count_unique})\")\n",
    "\n",
    "        return df_dim_loaded\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gravar dimensão {table_name}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9a9a6",
   "metadata": {},
   "source": [
    "### Dimensão Tempo\n",
    "\n",
    "A dimensão tempo é utilizada para:\n",
    "- data do acidente\n",
    "- data de emissão da CAT\n",
    "- data de nascimento do trabalhador\n",
    "\n",
    "Ela permite análises temporais como sazonalidade, tendências e comparações anuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97362879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_tempo(df_silver):    \n",
    "    df_datas = df_silver.select(\"data_acidente_referencia\").distinct() \\\n",
    "        .union(df_silver.select(\"data_emissao_cat\").distinct()) \\\n",
    "        .union(df_silver.select(\"data_nascimento\").distinct()) \\\n",
    "        .withColumnRenamed(\"data_acidente_referencia\", \"data\") \\\n",
    "        .distinct() \\\n",
    "        .dropna()\n",
    "    \n",
    "    df_tempo = df_datas.select(\n",
    "        col(\"data\"),\n",
    "        dayofmonth(\"data\").alias(\"dia\"),\n",
    "        month(\"data\").alias(\"mes\"),\n",
    "        date_format(\"data\", \"MMMM\").alias(\"nome_mes\"),\n",
    "        quarter(\"data\").alias(\"trimestre\"),\n",
    "        year(\"data\").alias(\"ano\"),\n",
    "        dayofweek(\"data\").alias(\"dia_semana\"),\n",
    "        when(dayofweek(\"data\").isin(1, 7), True).otherwise(False).alias(\"is_fim_semana\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_tempo,\n",
    "        \"tmp\",\n",
    "        \"data\",\n",
    "        [\"dia\", \"mes\", \"nome_mes\", \"trimestre\", \"ano\", \"dia_semana\", \"is_fim_semana\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d636630",
   "metadata": {},
   "source": [
    "### Dimensão Trabalhador\n",
    "\n",
    "Representa características demográficas e ocupacionais do trabalhador\n",
    "no momento do acidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_trabalhador(df_silver):\n",
    "    df_trabalhador = df_silver.select(\n",
    "        concat_ws(\"_\", \n",
    "                  upper(trim(col(\"sexo\"))),\n",
    "                  col(\"cbo_codigo_descricao\"),\n",
    "                  col(\"data_nascimento\")\n",
    "        ).alias(\"srk_trb\"),\n",
    "        upper(trim(col(\"sexo\"))).alias(\"sexo\"),\n",
    "        col(\"cbo_codigo_descricao\").alias(\"srk_cbo\"),\n",
    "        col(\"data_nascimento\").alias(\"srk_tmp_nsc\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_trabalhador,\n",
    "        \"trb\",\n",
    "        \"srk_trb\",\n",
    "        [\"sexo\", \"srk_cbo\", \"srk_tmp_nsc\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e7142",
   "metadata": {},
   "source": [
    "### Dimensão Empregador\n",
    "\n",
    "A dimensão empregador representa as características da empresa\n",
    "responsável pelo vínculo de trabalho no momento do acidente.\n",
    "\n",
    "Esta dimensão referencia:\n",
    "- a dimensão CNAE (atividade econômica)\n",
    "- a dimensão Município (localização do empregador)\n",
    "\n",
    "Sua criação ocorre após a carga das dimensões independentes,\n",
    "garantindo integridade referencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fab3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_empregador(df_silver):\n",
    "    df_empregador = df_silver.select(\n",
    "        concat_ws(\"_\", \n",
    "                  col(\"cnae_empregador\"),\n",
    "                  col(\"municipio_empregador\")\n",
    "        ).alias(\"srk_emp\"),\n",
    "        col(\"cnae_empregador\").alias(\"srk_cne\"),\n",
    "        col(\"municipio_empregador\").alias(\"srk_mnc\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_empregador,\n",
    "        \"emp\",\n",
    "        \"srk_emp\",\n",
    "        [\"srk_cne\", \"srk_mnc\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7ebba",
   "metadata": {},
   "source": [
    "### Dimensões de Classificação\n",
    "\n",
    "As dimensões a seguir representam classificações oficiais utilizadas\n",
    "para padronização e análise estatística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa325a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_cbo(df_silver):\n",
    "    df_cbo = df_silver.select(\n",
    "        col(\"cbo_codigo_descricao\").alias(\"srk_cbo\"),\n",
    "        col(\"cbo_codigo_descricao\").alias(\"codigo\"),\n",
    "        col(\"cbo_codigo_descricao\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cbo,\n",
    "        \"cbo\",\n",
    "        \"srk_cbo\",\n",
    "        [\"codigo\", \"descricao\"],\n",
    "        conn_params\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dim_cnae(df_silver):\n",
    "    df_cnae = df_silver.select(\n",
    "        col(\"cnae_empregador\").alias(\"srk_cne\"),\n",
    "        col(\"cnae_empregador\").alias(\"codigo\"),\n",
    "        col(\"cnae_empregador_descricao\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cnae,\n",
    "        \"cne\",\n",
    "        \"srk_cne\",\n",
    "        [\"codigo\", \"descricao\"],\n",
    "        conn_params\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dim_cid10(df_silver):\n",
    "    df_cid = df_silver.select(\n",
    "        col(\"cid_10\").alias(\"srk_cid\"),\n",
    "        col(\"cid_10\").alias(\"codigo\"),\n",
    "        col(\"cid_10\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_cid,\n",
    "        \"cid\",\n",
    "        \"srk_cid\",\n",
    "        [\"codigo\", \"descricao\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfc0b7",
   "metadata": {},
   "source": [
    "### Dimensão Município\n",
    "\n",
    "A dimensão município é utilizada para:\n",
    "- local do acidente\n",
    "- local do empregador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8f1f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_municipio(df_silver):\n",
    "    df_mun_acidente = df_silver.select(\n",
    "        col(\"uf_municipio_acidente\").alias(\"codigo_ibge\"),\n",
    "        col(\"uf_municipio_acidente\").alias(\"nome\"),\n",
    "        col(\"uf_municipio_acidente\").alias(\"uf\")\n",
    "    )\n",
    "    \n",
    "    df_mun_empregador = df_silver.select(\n",
    "        col(\"municipio_empregador\").alias(\"codigo_ibge\"),\n",
    "        col(\"municipio_empregador\").alias(\"nome\"),\n",
    "        col(\"uf_municipio_empregador\").alias(\"uf\")\n",
    "    )\n",
    "    \n",
    "    df_municipio = df_mun_acidente.union(df_mun_empregador) \\\n",
    "        .distinct() \\\n",
    "        .dropna(subset=[\"codigo_ibge\"])\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_municipio,\n",
    "        \"mnc\",\n",
    "        \"codigo_ibge\",\n",
    "        [\"nome\", \"uf\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003ff7f",
   "metadata": {},
   "source": [
    "### Dimensões de Caracterização do Acidente\n",
    "\n",
    "Estas dimensões descrevem o contexto e as causas do acidente de trabalho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f16d4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dim_tipo_acidente(df_silver):    \n",
    "    df_tipo_acidente = df_silver.select(\n",
    "        col(\"tipo_acidente\").alias(\"srk_tpo_act\"),\n",
    "        col(\"tipo_acidente\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_tipo_acidente,\n",
    "        \"tpo_act\",\n",
    "        \"srk_tpo_act\",\n",
    "        [\"descricao\"],\n",
    "        conn_params\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dim_lesao(df_silver):\n",
    "    df_lesao = df_silver.select(\n",
    "        concat_ws(\"_\", \n",
    "                  col(\"natureza_lesao\"), \n",
    "                  col(\"parte_corpo_atingida\")\n",
    "        ).alias(\"srk_lso\"),\n",
    "        col(\"natureza_lesao\").alias(\"natureza_lesao\"),\n",
    "        col(\"parte_corpo_atingida\").alias(\"parte_corpo_atingida\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_lesao,\n",
    "        \"lso\",\n",
    "        \"srk_lso\",\n",
    "        [\"natureza_lesao\", \"parte_corpo_atingida\"],\n",
    "        conn_params\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dim_agente_causador(df_silver):\n",
    "    df_agente = df_silver.select(\n",
    "        col(\"agente_causador_acidente\").alias(\"srk_agt_cdr\"),\n",
    "        col(\"agente_causador_acidente\").alias(\"descricao\")\n",
    "    )\n",
    "    \n",
    "    return save_dimension(\n",
    "        df_agente,\n",
    "        \"agt_cdr\",\n",
    "        \"srk_agt_cdr\",\n",
    "        [\"descricao\"],\n",
    "        conn_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e3256",
   "metadata": {},
   "source": [
    "## Execução da Carga das Dimensões\n",
    "\n",
    "Nesta etapa é executado o processo completo de criação e carga das dimensões,\n",
    "respeitando a ordem de dependência entre elas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0897f02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 18083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão carregada. Registros confirmados: 18083\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_cbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão carregada. Registros confirmados: 1647\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_mnc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmados (3304) < esperados (3311)\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_cne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão carregada. Registros confirmados: 663\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_tpo_act\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n",
      "Dimensão carregada. Registros confirmados: 3\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_lso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão carregada. Registros confirmados: 852\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_agt_cdr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n",
      "Dimensão carregada. Registros confirmados: 296\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_cid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão carregada. Registros confirmados: 1916\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_trb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 132473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão carregada. Registros confirmados: 132473\n",
      "\n",
      "---> Criando e carregando Dimensão: gold.dim_emp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Registros únicos: 39659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserção concluída\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51658/2498911532.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pdf = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão carregada. Registros confirmados: 39659\n",
      "Dimensões foram carregadas\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dim_tempo = create_dim_tempo(df_silver)          \n",
    "    dim_cbo = create_dim_cbo(df_silver)            \n",
    "    dim_municipio = create_dim_municipio(df_silver)      \n",
    "    dim_cnae = create_dim_cnae(df_silver)           \n",
    "    dim_tipo_acidente = create_dim_tipo_acidente(df_silver)  \n",
    "    dim_lesao = create_dim_lesao(df_silver)          \n",
    "    dim_agente_causador = create_dim_agente_causador(df_silver)\n",
    "    dim_cid10 = create_dim_cid10(df_silver)          \n",
    "\n",
    "    dim_trabalhador = create_dim_trabalhador(df_silver)\n",
    "    dim_empregador = create_dim_empregador(df_silver)\n",
    "        \n",
    "    print(\"Dimensões foram carregadas\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nERRO NA CARGA DAS DIMENSÕES: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5dbab",
   "metadata": {},
   "source": [
    "### Preparando dados da camada Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "661cdb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:=======>                                                 (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros preparados: 145888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat_ws, upper, trim, year, lit\n",
    "\n",
    "# Transformações iniciais e criação de chaves compostas\n",
    "df_base = df_silver.select(\n",
    "    # Chave SRK Categoria\n",
    "    concat_ws(\"_\",\n",
    "        col(\"data_acidente_referencia\"),\n",
    "        col(\"sexo\"),\n",
    "        col(\"cbo_codigo_descricao\"),\n",
    "        col(\"cnae_empregador\"),\n",
    "        col(\"municipio_empregador\")\n",
    "    ).alias(\"srk_cat\"),\n",
    "    \n",
    "    # Chave SRK Trabalhador\n",
    "    concat_ws(\"_\", \n",
    "        upper(trim(col(\"sexo\"))),\n",
    "        col(\"cbo_codigo_descricao\"),\n",
    "        col(\"data_nascimento\")\n",
    "    ).alias(\"srk_trb\"),\n",
    "\n",
    "    # Chave SRK Empregador\n",
    "    concat_ws(\"_\", \n",
    "        col(\"cnae_empregador\"),\n",
    "        col(\"municipio_empregador\")\n",
    "    ).alias(\"srk_emp\"),\n",
    "\n",
    "    # Chave composta para Lesão (Trazido da célula 2 para cá)\n",
    "    concat_ws(\"_\", \n",
    "        col(\"natureza_lesao\"), \n",
    "        col(\"parte_corpo_atingida\")\n",
    "    ).alias(\"lesao_join_key\"),\n",
    "\n",
    "    # Renomeações diretas e colunas de dados\n",
    "    col(\"data_acidente_referencia\").alias(\"data_acidente\"),\n",
    "    col(\"data_emissao_cat\").alias(\"data_emissao\"),\n",
    "    col(\"data_nascimento\"),\n",
    "    col(\"cbo_codigo_descricao\").alias(\"codigo_cbo\"),\n",
    "    col(\"cnae_empregador\").alias(\"codigo_cnae\"),\n",
    "    col(\"uf_municipio_acidente\").alias(\"codigo_municipio_acidente\"),\n",
    "    col(\"municipio_empregador\").alias(\"codigo_municipio_empregador\"),\n",
    "    col(\"tipo_acidente\").alias(\"codigo_tipo_acidente\"),\n",
    "    col(\"agente_causador_acidente\").alias(\"codigo_agente_causador\"),\n",
    "    col(\"cid_10\").alias(\"codigo_cid10\"),\n",
    "\n",
    "    # Cálculo de idade\n",
    "    (year(col(\"data_acidente_referencia\")) - year(col(\"data_nascimento\"))).cast(\"int\").alias(\"idade_trabalhador\")\n",
    ")\n",
    "\n",
    "print(f\"Registros preparados: {df_base.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e713af6-7415-4587-8e31-4d021e2111df",
   "metadata": {},
   "source": [
    "## Lookup de Surrogate Keys\n",
    "\n",
    "Realiza joins (lookups) entre df_base e todas as dimensões\n",
    "para substituir business keys por surrogate keys (FKs).\n",
    "\n",
    "- Trocar valores de negócio por IDs técnicos (surrogate keys)\n",
    "- Criar relacionamentos entre fato e dimensões\n",
    "- Preparar estrutura final da tabela fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274d1746-9fe4-4888-87b2-caca064c0eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema após joins:\n",
      "root\n",
      " |-- srk_cat: string (nullable = false)\n",
      " |-- idade_trabalhador: integer (nullable = true)\n",
      " |-- srk_tmp_act: long (nullable = true)\n",
      " |-- srk_tmp_ems: long (nullable = true)\n",
      " |-- srk_tmp_nsc: long (nullable = true)\n",
      " |-- srk_trb: long (nullable = true)\n",
      " |-- srk_cbo: long (nullable = true)\n",
      " |-- srk_emp: long (nullable = true)\n",
      " |-- srk_cne: long (nullable = true)\n",
      " |-- srk_mnc_act: long (nullable = true)\n",
      " |-- srk_mnc_emp: long (nullable = true)\n",
      " |-- srk_tpo_act: long (nullable = true)\n",
      " |-- srk_lso: long (nullable = true)\n",
      " |-- srk_agt_cdr: long (nullable = true)\n",
      " |-- srk_cid: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Célula 2: Loop de Joins Corrigido\n",
    "\n",
    "# Lista de configurações dos Joins\n",
    "# (DataFrame Dimensão, Coluna Chave Dimensão, Coluna Chave Fato, Coluna SRK Original, Novo Nome SRK)\n",
    "join_specs = [\n",
    "    (dim_tempo, \"chv_tmp_org\", \"data_acidente\", \"srk_tmp\", \"srk_tmp_act\"),\n",
    "    (dim_tempo, \"chv_tmp_org\", \"data_emissao\", \"srk_tmp\", \"srk_tmp_ems\"),\n",
    "    (dim_tempo, \"chv_tmp_org\", \"data_nascimento\", \"srk_tmp\", \"srk_tmp_nsc\"),\n",
    "    (dim_trabalhador, \"chv_trb_org\", \"srk_trb\", \"srk_trb\", \"srk_trb\"),\n",
    "    (dim_cbo, \"chv_cbo_org\", \"codigo_cbo\", \"srk_cbo\", \"srk_cbo\"),\n",
    "    (dim_empregador, \"chv_emp_org\", \"srk_emp\", \"srk_emp\", \"srk_emp\"),\n",
    "    (dim_cnae, \"chv_cne_org\", \"codigo_cnae\", \"srk_cne\", \"srk_cne\"),\n",
    "    (dim_municipio, \"chv_mnc_org\", \"codigo_municipio_acidente\", \"srk_mnc\", \"srk_mnc_act\"),\n",
    "    (dim_municipio, \"chv_mnc_org\", \"codigo_municipio_empregador\", \"srk_mnc\", \"srk_mnc_emp\"),\n",
    "    (dim_tipo_acidente, \"chv_tpo_act_org\", \"codigo_tipo_acidente\", \"srk_tpo_act\", \"srk_tpo_act\"),\n",
    "    (dim_lesao, \"chv_lso_org\", \"lesao_join_key\", \"srk_lso\", \"srk_lso\"),\n",
    "    (dim_agente_causador, \"chv_agt_cdr_org\", \"codigo_agente_causador\", \"srk_agt_cdr\", \"srk_agt_cdr\"),\n",
    "    (dim_cid10, \"chv_cid_org\", \"codigo_cid10\", \"srk_cid\", \"srk_cid\")\n",
    "]\n",
    "\n",
    "df_fact = df_base\n",
    "\n",
    "for dim_df, dim_key, fact_key, dim_srk, fact_alias in join_specs:\n",
    "    \n",
    "    # 1. Definimos um nome temporário para evitar colisão (Ambiguous Reference)\n",
    "    # Isso acontece porque, por exemplo, 'srk_trb' existe tanto na fato quanto na dimensão\n",
    "    temp_col_name = f\"{fact_alias}_temp_new\"\n",
    "    \n",
    "    lookup_dim = dim_df.select(\n",
    "        col(dim_key).alias(\"join_key_dim\"), \n",
    "        col(dim_srk).alias(temp_col_name) # Usamos o nome temporário aqui\n",
    "    )\n",
    "    \n",
    "    df_fact = df_fact.join(\n",
    "        lookup_dim,\n",
    "        col(fact_key) == col(\"join_key_dim\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    \n",
    "    # 2. Removemos a chave auxiliar E a coluna original da fato (ex: removemos a srk_trb string antiga)\n",
    "    df_fact = df_fact.drop(\"join_key_dim\", fact_key)\n",
    "    \n",
    "    # 3. Renomeamos a coluna temporária para o nome final desejado\n",
    "    df_fact = df_fact.withColumnRenamed(temp_col_name, fact_alias)\n",
    "\n",
    "# Verificação opcional para garantir que não restaram colunas duplicadas\n",
    "print(\"Schema após joins:\")\n",
    "df_fact.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c31259",
   "metadata": {},
   "source": [
    "## Montagem da Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4226f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 166:>                                                        (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros na tabela fato: 145870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Seleção final e reordenação das colunas\n",
    "cols_final = [\n",
    "    col(\"srk_cat\").alias(\"chv_cat_org\"),\n",
    "    \"srk_tmp_act\", \"srk_tmp_ems\", \"srk_tmp_nsc\",\n",
    "    \"srk_trb\", \"srk_cbo\", \"srk_emp\", \"srk_cne\",\n",
    "    \"srk_mnc_act\", \"srk_mnc_emp\",\n",
    "    \"srk_tpo_act\", \"srk_lso\", \"srk_agt_cdr\", \"srk_cid\",\n",
    "    \"idade_trabalhador\"\n",
    "]\n",
    "\n",
    "df_fact_final = df_fact.select(*cols_final).distinct()\n",
    "\n",
    "print(f\"Registros na tabela fato: {df_fact_final.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab941368",
   "metadata": {},
   "source": [
    "### Carga da Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec69d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas: 15\n",
      "Colunas a inserir: ['chv_cat_org', 'srk_tmp_act', 'srk_tmp_ems', 'srk_tmp_nsc', 'srk_trb', 'srk_cbo', 'srk_emp', 'srk_cne', 'srk_mnc_act', 'srk_mnc_emp', 'srk_tpo_act', 'srk_lso', 'srk_agt_cdr', 'srk_cid', 'idade_trabalhador']\n",
      "\n",
      "Preparando dados para inserção...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "colunas = df_fact_final.columns\n",
    "fact_table_name = f\"{GOLD_SCHEMA}.fat_act_trb\"\n",
    "\n",
    "print(f\"Colunas: {len(colunas)}\")\n",
    "print(f\"Colunas a inserir: {colunas}\")\n",
    "print(f\"\\nPreparando dados para inserção...\")\n",
    "\n",
    "dados_para_inserir = [tuple(row) for row in df_fact_final.collect()]\n",
    "\n",
    "conn = None\n",
    "cursor = None\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    query = f\"INSERT INTO {fact_table_name} ({', '.join(colunas)}) VALUES %s\"\n",
    "    \n",
    "    extras.execute_values(\n",
    "        cursor,\n",
    "        query,\n",
    "        dados_para_inserir,\n",
    "        template=None,\n",
    "        page_size=1000\n",
    "    )\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"Registros concluída com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro ao inserir dados: {e}\")\n",
    "    if conn:\n",
    "        conn.rollback()\n",
    "    raise e\n",
    "    \n",
    "finally:\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
